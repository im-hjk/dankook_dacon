{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "DACON_stacking을이겨버린lgbm-optuna_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/im-hjk/dankook_dacon/blob/master/DACON_stacking%EC%9D%84%EC%9D%B4%EA%B2%A8%EB%B2%84%EB%A6%B0lgbm_optuna_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQO3ZDmBtjqs"
      },
      "source": [
        "## 라이브러리 import 및 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:38:53.774831Z",
          "start_time": "2020-10-05T08:38:53.486186Z"
        },
        "id": "qn1gjvrztjqs"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcivVXRktpSs",
        "outputId": "c4ac2c50-f23c-4f38-aac9-d4c764fe31f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joqviwl6YyKk",
        "outputId": "9c5536a9-fcd1-4012-ad1e-e94ef136ae34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: cmaes>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (0.6.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.6/dist-packages (from optuna) (4.4.0)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.6/dist-packages (from optuna) (3.4.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.16.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.19)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
            "Requirement already satisfied: cmd2!=0.8.3,>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.3.11)\n",
            "Requirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.2.2)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (5.5.0)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.15.0)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (1.0.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (1.1.3)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=34.4 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (50.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata>=1.6.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (2.0.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (20.2.0)\n",
            "Requirement already satisfied: colorama>=0.3.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.4.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2!=0.8.3,>=0.8.0->cliff->optuna) (3.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:53:10.431515Z",
          "start_time": "2020-10-05T08:53:10.398638Z"
        },
        "id": "pzap0TBItjqv"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "import numpy as np\n",
        "import optuna.integration.lightgbm as lgb\n",
        "import io\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import seaborn as sns\n",
        "import warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:38:55.047271Z",
          "start_time": "2020-10-05T08:38:55.018323Z"
        },
        "id": "zfM-EoMgtjqw"
      },
      "source": [
        "rcParams['figure.figsize'] = (16, 8)\n",
        "plt.style.use('fivethirtyeight')\n",
        "pd.set_option('max_columns', 100)\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0Ql9nIatjqy"
      },
      "source": [
        "## 학습데이터 로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvKV8Ffotjqy"
      },
      "source": [
        "[03-pandas-eda.ipynb](https://github.com/kaggler-tv/dku-kaggle-class/blob/master/notebook/03-pandas-eda.ipynb)에서 생성한 `feature.csv` 피처파일 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:38:55.079180Z",
          "start_time": "2020-10-05T08:38:55.050994Z"
        },
        "id": "-K3cOAkptjqz"
      },
      "source": [
        "main_path = Path('/content/drive/My Drive/Colab Notebooks/dacon_dkdkdk')\n",
        "data_dir = main_path / 'data/dacon-dku'\n",
        "feature_dir = main_path / 'build/feature'\n",
        "val_dir = main_path / 'build/val'\n",
        "tst_dir = main_path / 'build/tst'\n",
        "sub_dir = main_path / 'build/sub'\n",
        "\n",
        "trn_file = data_dir / 'train.csv'\n",
        "tst_file = data_dir / 'test.csv'\n",
        "sample_file = data_dir / 'sample_submission.csv'\n",
        "\n",
        "target_col = 'class'\n",
        "n_fold = 5\n",
        "n_class = 3\n",
        "seed = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:38:55.109220Z",
          "start_time": "2020-10-05T08:38:55.081365Z"
        },
        "id": "bTUqeLqNtjq1"
      },
      "source": [
        "algo_name = 'lgb_optuna'\n",
        "feature_name = 'feature'\n",
        "model_name = f'{algo_name}_{feature_name}'\n",
        "\n",
        "feature_file = feature_dir / f'{feature_name}.csv'\n",
        "p_val_file = val_dir / f'{model_name}.val.csv'\n",
        "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
        "sub_file = sub_dir / f'{model_name}.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:38:56.480522Z",
          "start_time": "2020-10-05T08:38:55.111305Z"
        },
        "id": "tNAnzJkptjq2",
        "outputId": "7a544a77-27f7-46e8-e8a6-8a1bedd7d62a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "df = pd.read_csv(feature_file, index_col=0)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400000, 29)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>z</th>\n",
              "      <th>redshift</th>\n",
              "      <th>dered_u</th>\n",
              "      <th>dered_g</th>\n",
              "      <th>dered_r</th>\n",
              "      <th>dered_i</th>\n",
              "      <th>dered_z</th>\n",
              "      <th>nDetect</th>\n",
              "      <th>class</th>\n",
              "      <th>airmass</th>\n",
              "      <th>n_obMde</th>\n",
              "      <th>d_dered_u</th>\n",
              "      <th>d_dered_g</th>\n",
              "      <th>d_dered_r</th>\n",
              "      <th>d_dered_i</th>\n",
              "      <th>d_dered_z</th>\n",
              "      <th>u/g</th>\n",
              "      <th>u/r</th>\n",
              "      <th>u/i</th>\n",
              "      <th>u/z</th>\n",
              "      <th>g/i</th>\n",
              "      <th>g/z</th>\n",
              "      <th>r/i</th>\n",
              "      <th>r/z</th>\n",
              "      <th>i/z</th>\n",
              "      <th>d_dered_ig</th>\n",
              "      <th>d_dered_zg</th>\n",
              "      <th>d_dered_rz</th>\n",
              "      <th>d_dered_iz</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16.9396</td>\n",
              "      <td>-8.1086e-05</td>\n",
              "      <td>23.1243</td>\n",
              "      <td>20.2578</td>\n",
              "      <td>18.9551</td>\n",
              "      <td>17.6321</td>\n",
              "      <td>16.9089</td>\n",
              "      <td>18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.1898</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.1397</td>\n",
              "      <td>-0.0790</td>\n",
              "      <td>-0.0544</td>\n",
              "      <td>-0.0403</td>\n",
              "      <td>-0.0307</td>\n",
              "      <td>1.1439</td>\n",
              "      <td>1.2238</td>\n",
              "      <td>1.3164</td>\n",
              "      <td>1.3733</td>\n",
              "      <td>1.1508</td>\n",
              "      <td>1.2005</td>\n",
              "      <td>1.0757</td>\n",
              "      <td>1.1222</td>\n",
              "      <td>1.0433</td>\n",
              "      <td>-2.6257</td>\n",
              "      <td>-3.3488</td>\n",
              "      <td>2.0462</td>\n",
              "      <td>0.7232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.1689</td>\n",
              "      <td>4.5061e-03</td>\n",
              "      <td>14.9664</td>\n",
              "      <td>14.0045</td>\n",
              "      <td>13.4114</td>\n",
              "      <td>13.2363</td>\n",
              "      <td>13.1347</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2533</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.0857</td>\n",
              "      <td>-0.0574</td>\n",
              "      <td>-0.0410</td>\n",
              "      <td>-0.0322</td>\n",
              "      <td>-0.0343</td>\n",
              "      <td>1.0704</td>\n",
              "      <td>1.1189</td>\n",
              "      <td>1.1344</td>\n",
              "      <td>1.1430</td>\n",
              "      <td>1.0598</td>\n",
              "      <td>1.0678</td>\n",
              "      <td>1.0139</td>\n",
              "      <td>1.0215</td>\n",
              "      <td>1.0076</td>\n",
              "      <td>-0.7683</td>\n",
              "      <td>-0.8698</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.1016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15.3500</td>\n",
              "      <td>4.7198e-04</td>\n",
              "      <td>16.6076</td>\n",
              "      <td>15.6866</td>\n",
              "      <td>15.4400</td>\n",
              "      <td>15.3217</td>\n",
              "      <td>15.2961</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0225</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.1787</td>\n",
              "      <td>-0.1388</td>\n",
              "      <td>-0.0963</td>\n",
              "      <td>-0.0718</td>\n",
              "      <td>-0.0540</td>\n",
              "      <td>1.0607</td>\n",
              "      <td>1.0805</td>\n",
              "      <td>1.0905</td>\n",
              "      <td>1.0936</td>\n",
              "      <td>1.0281</td>\n",
              "      <td>1.0310</td>\n",
              "      <td>1.0093</td>\n",
              "      <td>1.0121</td>\n",
              "      <td>1.0028</td>\n",
              "      <td>-0.3649</td>\n",
              "      <td>-0.3905</td>\n",
              "      <td>0.1440</td>\n",
              "      <td>0.0257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19.6346</td>\n",
              "      <td>5.8143e-06</td>\n",
              "      <td>25.3536</td>\n",
              "      <td>20.9947</td>\n",
              "      <td>20.0873</td>\n",
              "      <td>19.7947</td>\n",
              "      <td>19.5552</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.2054</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.3070</td>\n",
              "      <td>-0.1941</td>\n",
              "      <td>-0.1339</td>\n",
              "      <td>-0.1003</td>\n",
              "      <td>-0.0795</td>\n",
              "      <td>1.2111</td>\n",
              "      <td>1.2690</td>\n",
              "      <td>1.2898</td>\n",
              "      <td>1.3069</td>\n",
              "      <td>1.0650</td>\n",
              "      <td>1.0791</td>\n",
              "      <td>1.0164</td>\n",
              "      <td>1.0299</td>\n",
              "      <td>1.0133</td>\n",
              "      <td>-1.2000</td>\n",
              "      <td>-1.4395</td>\n",
              "      <td>0.5321</td>\n",
              "      <td>0.2395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.9826</td>\n",
              "      <td>-3.3247e-05</td>\n",
              "      <td>23.7714</td>\n",
              "      <td>20.4338</td>\n",
              "      <td>18.8630</td>\n",
              "      <td>18.1903</td>\n",
              "      <td>17.8759</td>\n",
              "      <td>12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.1940</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.6820</td>\n",
              "      <td>-0.2653</td>\n",
              "      <td>-0.1794</td>\n",
              "      <td>-0.1339</td>\n",
              "      <td>-0.1067</td>\n",
              "      <td>1.1814</td>\n",
              "      <td>1.2842</td>\n",
              "      <td>1.3345</td>\n",
              "      <td>1.3598</td>\n",
              "      <td>1.1296</td>\n",
              "      <td>1.1511</td>\n",
              "      <td>1.0392</td>\n",
              "      <td>1.0589</td>\n",
              "      <td>1.0190</td>\n",
              "      <td>-2.2436</td>\n",
              "      <td>-2.5579</td>\n",
              "      <td>0.9871</td>\n",
              "      <td>0.3144</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          z    redshift  dered_u  dered_g  dered_r  dered_i  dered_z  nDetect  \\\n",
              "id                                                                              \n",
              "0   16.9396 -8.1086e-05  23.1243  20.2578  18.9551  17.6321  16.9089       18   \n",
              "1   13.1689  4.5061e-03  14.9664  14.0045  13.4114  13.2363  13.1347        1   \n",
              "2   15.3500  4.7198e-04  16.6076  15.6866  15.4400  15.3217  15.2961        2   \n",
              "3   19.6346  5.8143e-06  25.3536  20.9947  20.0873  19.7947  19.5552        3   \n",
              "4   17.9826 -3.3247e-05  23.7714  20.4338  18.8630  18.1903  17.8759       12   \n",
              "\n",
              "    class  airmass  n_obMde  d_dered_u  d_dered_g  d_dered_r  d_dered_i  \\\n",
              "id                                                                        \n",
              "0     0.0   1.1898        0    -0.1397    -0.0790    -0.0544    -0.0403   \n",
              "1     1.0   1.2533        0    -0.0857    -0.0574    -0.0410    -0.0322   \n",
              "2     0.0   1.0225        0    -0.1787    -0.1388    -0.0963    -0.0718   \n",
              "3     0.0   1.2054        1    -0.3070    -0.1941    -0.1339    -0.1003   \n",
              "4     0.0   1.1940        1    -0.6820    -0.2653    -0.1794    -0.1339   \n",
              "\n",
              "    d_dered_z     u/g     u/r     u/i     u/z     g/i     g/z     r/i     r/z  \\\n",
              "id                                                                              \n",
              "0     -0.0307  1.1439  1.2238  1.3164  1.3733  1.1508  1.2005  1.0757  1.1222   \n",
              "1     -0.0343  1.0704  1.1189  1.1344  1.1430  1.0598  1.0678  1.0139  1.0215   \n",
              "2     -0.0540  1.0607  1.0805  1.0905  1.0936  1.0281  1.0310  1.0093  1.0121   \n",
              "3     -0.0795  1.2111  1.2690  1.2898  1.3069  1.0650  1.0791  1.0164  1.0299   \n",
              "4     -0.1067  1.1814  1.2842  1.3345  1.3598  1.1296  1.1511  1.0392  1.0589   \n",
              "\n",
              "       i/z  d_dered_ig  d_dered_zg  d_dered_rz  d_dered_iz  \n",
              "id                                                          \n",
              "0   1.0433     -2.6257     -3.3488      2.0462      0.7232  \n",
              "1   1.0076     -0.7683     -0.8698      0.2767      0.1016  \n",
              "2   1.0028     -0.3649     -0.3905      0.1440      0.0257  \n",
              "3   1.0133     -1.2000     -1.4395      0.5321      0.2395  \n",
              "4   1.0190     -2.2436     -2.5579      0.9871      0.3144  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:38:56.553068Z",
          "start_time": "2020-10-05T08:38:56.482710Z"
        },
        "id": "gZRrzhRItjq4",
        "outputId": "cec6da33-2d45-432d-aece-bd6fd58af47b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y = df[target_col].values[:320000]\n",
        "df.drop(target_col, axis=1, inplace=True)\n",
        "trn = df.iloc[:320000].values\n",
        "tst = df.iloc[320000:].values\n",
        "feature_name = df.columns.tolist()\n",
        "print(y.shape, trn.shape, tst.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(320000,) (320000, 28) (80000, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bay1xNjtjq6"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:38:56.690768Z",
          "start_time": "2020-10-05T08:38:56.556065Z"
        },
        "id": "m1npBi5ctjq7"
      },
      "source": [
        "X_trn, X_val, y_trn, y_val = train_test_split(trn, y, test_size=.2, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:38:56.723614Z",
          "start_time": "2020-10-05T08:38:56.693535Z"
        },
        "id": "hJ_T8dHmtjq8"
      },
      "source": [
        "params = {\n",
        "    \"objective\": \"multiclass\",\n",
        "    \"metric\": \"multi_logloss\",\n",
        "    \"num_class\": 3,\n",
        "    \"n_estimators\": 3000,\n",
        "    \"subsample_freq\": 1,\n",
        "    \"lambda_l1\": 0.,\n",
        "    \"lambda_l2\": 0.,\n",
        "    \"random_state\": seed,\n",
        "    \"n_jobs\": -1,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:51:30.834862Z",
          "start_time": "2020-10-05T08:38:56.725742Z"
        },
        "id": "ZGlb467ytjq-",
        "outputId": "16c4e9da-dd8e-4132-881a-793ff2daa8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dtrain = lgb.Dataset(X_trn, label=y_trn)\n",
        "dval = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "model = lgb.train(params, dtrain, valid_sets=[dtrain, dval], \n",
        "                  verbose_eval=100, early_stopping_rounds=10)\n",
        "\n",
        "prediction = np.argmax(model.predict(X_val, num_iteration=model.best_iteration), \n",
        "                       axis=1)\n",
        "accuracy = accuracy_score(y_val, prediction)\n",
        "\n",
        "params = model.params\n",
        "print(\"Best params:\", params)\n",
        "print(\"  Accuracy = {}\".format(accuracy))\n",
        "print(\"  Params: \")\n",
        "for key, value in params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-10-09 08:04:34,104]\u001b[0m A new study created in memory with name: no-name-0169f949-097b-4cad-9489-639683bde26b\u001b[0m\n",
            "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.150635\tvalid_1's multi_logloss: 0.163905\n",
            "[200]\ttraining's multi_logloss: 0.138147\tvalid_1's multi_logloss: 0.16072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 0.159674:  14%|#4        | 1/7 [00:45<04:34, 45.72s/it]\u001b[32m[I 2020-10-09 08:05:19,838]\u001b[0m Trial 0 finished with value: 0.1596735256743699 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.1596735256743699.\u001b[0m\n",
            "feature_fraction, val_score: 0.159674:  14%|#4        | 1/7 [00:45<04:34, 45.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[289]\ttraining's multi_logloss: 0.130603\tvalid_1's multi_logloss: 0.159674\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.154048\tvalid_1's multi_logloss: 0.165613\n",
            "[200]\ttraining's multi_logloss: 0.140209\tvalid_1's multi_logloss: 0.160506\n",
            "[300]\ttraining's multi_logloss: 0.132047\tvalid_1's multi_logloss: 0.159359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 0.159160:  29%|##8       | 2/7 [01:25<03:39, 43.85s/it]\u001b[32m[I 2020-10-09 08:05:59,303]\u001b[0m Trial 1 finished with value: 0.15915963441656988 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.15915963441656988.\u001b[0m\n",
            "feature_fraction, val_score: 0.159160:  29%|##8       | 2/7 [01:25<03:39, 43.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[336]\ttraining's multi_logloss: 0.129622\tvalid_1's multi_logloss: 0.15916\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.15106\tvalid_1's multi_logloss: 0.163866\n",
            "[200]\ttraining's multi_logloss: 0.138467\tvalid_1's multi_logloss: 0.160175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 0.159160:  43%|####2     | 3/7 [02:11<02:57, 44.47s/it]\u001b[32m[I 2020-10-09 08:06:45,214]\u001b[0m Trial 2 finished with value: 0.15928339043760842 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.15915963441656988.\u001b[0m\n",
            "feature_fraction, val_score: 0.159160:  43%|####2     | 3/7 [02:11<02:57, 44.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[278]\ttraining's multi_logloss: 0.131821\tvalid_1's multi_logloss: 0.159283\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.15078\tvalid_1's multi_logloss: 0.163945\n",
            "[200]\ttraining's multi_logloss: 0.138098\tvalid_1's multi_logloss: 0.16045\n",
            "[300]\ttraining's multi_logloss: 0.129697\tvalid_1's multi_logloss: 0.159532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 0.159160:  57%|#####7    | 4/7 [03:02<02:19, 46.48s/it]\u001b[32m[I 2020-10-09 08:07:36,400]\u001b[0m Trial 3 finished with value: 0.15926431402445285 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.15915963441656988.\u001b[0m\n",
            "feature_fraction, val_score: 0.159160:  57%|#####7    | 4/7 [03:02<02:19, 46.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[346]\ttraining's multi_logloss: 0.126377\tvalid_1's multi_logloss: 0.159264\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.151586\tvalid_1's multi_logloss: 0.164353\n",
            "[200]\ttraining's multi_logloss: 0.138927\tvalid_1's multi_logloss: 0.160386\n",
            "[300]\ttraining's multi_logloss: 0.130618\tvalid_1's multi_logloss: 0.159228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rfeature_fraction, val_score: 0.158875:  57%|#####7    | 4/7 [03:49<02:19, 46.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[359]\ttraining's multi_logloss: 0.126501\tvalid_1's multi_logloss: 0.158875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 0.158875:  71%|#######1  | 5/7 [03:49<01:33, 46.69s/it]\u001b[32m[I 2020-10-09 08:08:23,587]\u001b[0m Trial 4 finished with value: 0.1588747356898734 and parameters: {'feature_fraction': 0.7}. Best is trial 4 with value: 0.1588747356898734.\u001b[0m\n",
            "feature_fraction, val_score: 0.158875:  71%|#######1  | 5/7 [03:49<01:33, 46.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.152449\tvalid_1's multi_logloss: 0.164452\n",
            "[200]\ttraining's multi_logloss: 0.139542\tvalid_1's multi_logloss: 0.160285\n",
            "[300]\ttraining's multi_logloss: 0.131343\tvalid_1's multi_logloss: 0.159348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 0.158875:  86%|########5 | 6/7 [04:30<00:44, 44.91s/it]\u001b[32m[I 2020-10-09 08:09:04,332]\u001b[0m Trial 5 finished with value: 0.1590574951091544 and parameters: {'feature_fraction': 0.6}. Best is trial 4 with value: 0.1588747356898734.\u001b[0m\n",
            "feature_fraction, val_score: 0.158875:  86%|########5 | 6/7 [04:30<00:44, 44.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[335]\ttraining's multi_logloss: 0.128859\tvalid_1's multi_logloss: 0.159057\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.156762\tvalid_1's multi_logloss: 0.167809\n",
            "[200]\ttraining's multi_logloss: 0.141257\tvalid_1's multi_logloss: 0.160545\n",
            "[300]\ttraining's multi_logloss: 0.133083\tvalid_1's multi_logloss: 0.159359\n",
            "[400]\ttraining's multi_logloss: 0.12644\tvalid_1's multi_logloss: 0.158752\n",
            "Early stopping, best iteration is:\n",
            "[406]\ttraining's multi_logloss: 0.126069\tvalid_1's multi_logloss: 0.158718\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 0.158718: 100%|##########| 7/7 [05:14<00:00, 44.64s/it]\u001b[32m[I 2020-10-09 08:09:48,340]\u001b[0m Trial 6 finished with value: 0.15871770282030861 and parameters: {'feature_fraction': 0.4}. Best is trial 6 with value: 0.15871770282030861.\u001b[0m\n",
            "feature_fraction, val_score: 0.158718: 100%|##########| 7/7 [05:14<00:00, 44.89s/it]\n",
            "num_leaves, val_score: 0.158718:   0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.130037\tvalid_1's multi_logloss: 0.161865\n",
            "[200]\ttraining's multi_logloss: 0.105674\tvalid_1's multi_logloss: 0.158305\n",
            "Early stopping, best iteration is:\n",
            "[198]\ttraining's multi_logloss: 0.106063\tvalid_1's multi_logloss: 0.158278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158278:   5%|5         | 1/20 [00:31<09:54, 31.29s/it]\u001b[32m[I 2020-10-09 08:10:19,640]\u001b[0m Trial 7 finished with value: 0.15827798783306576 and parameters: {'num_leaves': 121}. Best is trial 7 with value: 0.15827798783306576.\u001b[0m\n",
            "num_leaves, val_score: 0.158278:   5%|5         | 1/20 [00:31<09:54, 31.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.120332\tvalid_1's multi_logloss: 0.161474\n",
            "Early stopping, best iteration is:\n",
            "[185]\ttraining's multi_logloss: 0.0956357\tvalid_1's multi_logloss: 0.158607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158278:  10%|#         | 2/20 [01:04<09:32, 31.79s/it]\u001b[32m[I 2020-10-09 08:10:52,591]\u001b[0m Trial 8 finished with value: 0.15860713275912713 and parameters: {'num_leaves': 169}. Best is trial 7 with value: 0.15827798783306576.\u001b[0m\n",
            "num_leaves, val_score: 0.158278:  10%|#         | 2/20 [01:04<09:32, 31.79s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.166384\tvalid_1's multi_logloss: 0.173649\n",
            "[200]\ttraining's multi_logloss: 0.151842\tvalid_1's multi_logloss: 0.164594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158278:  15%|#5        | 3/20 [01:25<08:06, 28.63s/it]\u001b[32m[I 2020-10-09 08:11:13,841]\u001b[0m Trial 9 finished with value: 0.16371954254281748 and parameters: {'num_leaves': 17}. Best is trial 7 with value: 0.15827798783306576.\u001b[0m\n",
            "num_leaves, val_score: 0.158278:  15%|#5        | 3/20 [01:25<08:06, 28.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[195]\ttraining's multi_logloss: 0.152097\tvalid_1's multi_logloss: 0.16372\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.141858\tvalid_1's multi_logloss: 0.16375\n",
            "[200]\ttraining's multi_logloss: 0.121841\tvalid_1's multi_logloss: 0.159023\n",
            "Early stopping, best iteration is:\n",
            "[267]\ttraining's multi_logloss: 0.113196\tvalid_1's multi_logloss: 0.158647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158278:  20%|##        | 4/20 [02:01<08:14, 30.93s/it]\u001b[32m[I 2020-10-09 08:11:50,137]\u001b[0m Trial 10 finished with value: 0.15864732650755026 and parameters: {'num_leaves': 73}. Best is trial 7 with value: 0.15827798783306576.\u001b[0m\n",
            "num_leaves, val_score: 0.158278:  20%|##        | 4/20 [02:01<08:14, 30.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.113348\tvalid_1's multi_logloss: 0.161069\n",
            "Early stopping, best iteration is:\n",
            "[159]\ttraining's multi_logloss: 0.0937651\tvalid_1's multi_logloss: 0.158679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158278:  25%|##5       | 5/20 [02:33<07:45, 31.05s/it]\u001b[32m[I 2020-10-09 08:12:21,489]\u001b[0m Trial 11 finished with value: 0.15867928522155766 and parameters: {'num_leaves': 206}. Best is trial 7 with value: 0.15827798783306576.\u001b[0m\n",
            "num_leaves, val_score: 0.158278:  25%|##5       | 5/20 [02:33<07:45, 31.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.120332\tvalid_1's multi_logloss: 0.161474\n",
            "Early stopping, best iteration is:\n",
            "[185]\ttraining's multi_logloss: 0.0956357\tvalid_1's multi_logloss: 0.158607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158278:  30%|###       | 6/20 [03:06<07:22, 31.64s/it]\u001b[32m[I 2020-10-09 08:12:54,481]\u001b[0m Trial 12 finished with value: 0.15860713275912713 and parameters: {'num_leaves': 169}. Best is trial 7 with value: 0.15827798783306576.\u001b[0m\n",
            "num_leaves, val_score: 0.158278:  30%|###       | 6/20 [03:06<07:22, 31.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.130439\tvalid_1's multi_logloss: 0.161949\n",
            "[200]\ttraining's multi_logloss: 0.106144\tvalid_1's multi_logloss: 0.15817\n",
            "Early stopping, best iteration is:\n",
            "[195]\ttraining's multi_logloss: 0.106949\tvalid_1's multi_logloss: 0.158142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158142:  35%|###5      | 7/20 [03:37<06:50, 31.57s/it]\u001b[32m[I 2020-10-09 08:13:25,904]\u001b[0m Trial 13 finished with value: 0.158141968096901 and parameters: {'num_leaves': 119}. Best is trial 13 with value: 0.158141968096901.\u001b[0m\n",
            "num_leaves, val_score: 0.158142:  35%|###5      | 7/20 [03:37<06:50, 31.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.13318\tvalid_1's multi_logloss: 0.162519\n",
            "[200]\ttraining's multi_logloss: 0.109872\tvalid_1's multi_logloss: 0.158645\n",
            "Early stopping, best iteration is:\n",
            "[209]\ttraining's multi_logloss: 0.108356\tvalid_1's multi_logloss: 0.158582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158142:  40%|####      | 8/20 [04:09<06:21, 31.78s/it]\u001b[32m[I 2020-10-09 08:13:58,178]\u001b[0m Trial 14 finished with value: 0.15858150276862218 and parameters: {'num_leaves': 107}. Best is trial 13 with value: 0.158141968096901.\u001b[0m\n",
            "num_leaves, val_score: 0.158142:  40%|####      | 8/20 [04:09<06:21, 31.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.140916\tvalid_1's multi_logloss: 0.163599\n",
            "[200]\ttraining's multi_logloss: 0.120449\tvalid_1's multi_logloss: 0.158839\n",
            "Early stopping, best iteration is:\n",
            "[225]\ttraining's multi_logloss: 0.117083\tvalid_1's multi_logloss: 0.158724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158142:  45%|####5     | 9/20 [04:41<05:48, 31.71s/it]\u001b[32m[I 2020-10-09 08:14:29,735]\u001b[0m Trial 15 finished with value: 0.15872371185259504 and parameters: {'num_leaves': 76}. Best is trial 13 with value: 0.158141968096901.\u001b[0m\n",
            "num_leaves, val_score: 0.158142:  45%|####5     | 9/20 [04:41<05:48, 31.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.127619\tvalid_1's multi_logloss: 0.161906\n",
            "[200]\ttraining's multi_logloss: 0.102374\tvalid_1's multi_logloss: 0.15838\n",
            "Early stopping, best iteration is:\n",
            "[200]\ttraining's multi_logloss: 0.102374\tvalid_1's multi_logloss: 0.15838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158142:  50%|#####     | 10/20 [05:14<05:20, 32.01s/it]\u001b[32m[I 2020-10-09 08:15:02,443]\u001b[0m Trial 16 finished with value: 0.15838010193911947 and parameters: {'num_leaves': 132}. Best is trial 13 with value: 0.158141968096901.\u001b[0m\n",
            "num_leaves, val_score: 0.158142:  50%|#####     | 10/20 [05:14<05:20, 32.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.153701\tvalid_1's multi_logloss: 0.16653\n",
            "[200]\ttraining's multi_logloss: 0.137463\tvalid_1's multi_logloss: 0.160136\n",
            "[300]\ttraining's multi_logloss: 0.128285\tvalid_1's multi_logloss: 0.159202\n",
            "Early stopping, best iteration is:\n",
            "[332]\ttraining's multi_logloss: 0.125731\tvalid_1's multi_logloss: 0.159032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158142:  55%|#####5    | 11/20 [05:52<05:05, 33.93s/it]\u001b[32m[I 2020-10-09 08:15:40,847]\u001b[0m Trial 17 finished with value: 0.15903173090611714 and parameters: {'num_leaves': 38}. Best is trial 13 with value: 0.158141968096901.\u001b[0m\n",
            "num_leaves, val_score: 0.158142:  55%|#####5    | 11/20 [05:52<05:05, 33.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.128526\tvalid_1's multi_logloss: 0.161981\n",
            "[200]\ttraining's multi_logloss: 0.103772\tvalid_1's multi_logloss: 0.158297\n",
            "Early stopping, best iteration is:\n",
            "[202]\ttraining's multi_logloss: 0.103417\tvalid_1's multi_logloss: 0.158296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158142:  60%|######    | 12/20 [06:25<04:28, 33.58s/it]\u001b[32m[I 2020-10-09 08:16:13,620]\u001b[0m Trial 18 finished with value: 0.15829640629835348 and parameters: {'num_leaves': 128}. Best is trial 13 with value: 0.158141968096901.\u001b[0m\n",
            "num_leaves, val_score: 0.158142:  60%|######    | 12/20 [06:25<04:28, 33.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.105475\tvalid_1's multi_logloss: 0.161121\n",
            "Early stopping, best iteration is:\n",
            "[154]\ttraining's multi_logloss: 0.0862036\tvalid_1's multi_logloss: 0.159035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158142:  65%|######5   | 13/20 [07:05<04:08, 35.50s/it]\u001b[32m[I 2020-10-09 08:16:53,603]\u001b[0m Trial 19 finished with value: 0.159034608183395 and parameters: {'num_leaves': 256}. Best is trial 13 with value: 0.158141968096901.\u001b[0m\n",
            "num_leaves, val_score: 0.158142:  65%|######5   | 13/20 [07:05<04:08, 35.50s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.119413\tvalid_1's multi_logloss: 0.161594\n",
            "Early stopping, best iteration is:\n",
            "[174]\ttraining's multi_logloss: 0.0970844\tvalid_1's multi_logloss: 0.158827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158142:  70%|#######   | 14/20 [07:37<03:26, 34.47s/it]\u001b[32m[I 2020-10-09 08:17:25,675]\u001b[0m Trial 20 finished with value: 0.15882741141414938 and parameters: {'num_leaves': 173}. Best is trial 13 with value: 0.158141968096901.\u001b[0m\n",
            "num_leaves, val_score: 0.158142:  70%|#######   | 14/20 [07:37<03:26, 34.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.131599\tvalid_1's multi_logloss: 0.162316\n",
            "[200]\ttraining's multi_logloss: 0.107872\tvalid_1's multi_logloss: 0.158418\n",
            "Early stopping, best iteration is:\n",
            "[200]\ttraining's multi_logloss: 0.107872\tvalid_1's multi_logloss: 0.158418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158142:  75%|#######5  | 15/20 [08:08<02:47, 33.60s/it]\u001b[32m[I 2020-10-09 08:17:57,221]\u001b[0m Trial 21 finished with value: 0.1584182088677145 and parameters: {'num_leaves': 113}. Best is trial 13 with value: 0.158141968096901.\u001b[0m\n",
            "num_leaves, val_score: 0.158142:  75%|#######5  | 15/20 [08:08<02:47, 33.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.126708\tvalid_1's multi_logloss: 0.162025\n",
            "[200]\ttraining's multi_logloss: 0.101048\tvalid_1's multi_logloss: 0.158357\n",
            "Early stopping, best iteration is:\n",
            "[200]\ttraining's multi_logloss: 0.101048\tvalid_1's multi_logloss: 0.158357\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158142:  80%|########  | 16/20 [08:42<02:13, 33.49s/it]\u001b[32m[I 2020-10-09 08:18:30,470]\u001b[0m Trial 22 finished with value: 0.15835706770398303 and parameters: {'num_leaves': 136}. Best is trial 13 with value: 0.158141968096901.\u001b[0m\n",
            "num_leaves, val_score: 0.158142:  80%|########  | 16/20 [08:42<02:13, 33.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.139112\tvalid_1's multi_logloss: 0.163471\n",
            "[200]\ttraining's multi_logloss: 0.118074\tvalid_1's multi_logloss: 0.159043\n",
            "Early stopping, best iteration is:\n",
            "[241]\ttraining's multi_logloss: 0.112218\tvalid_1's multi_logloss: 0.158853\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158142:  85%|########5 | 17/20 [09:16<01:41, 33.77s/it]\u001b[32m[I 2020-10-09 08:19:04,893]\u001b[0m Trial 23 finished with value: 0.15885333739324664 and parameters: {'num_leaves': 83}. Best is trial 13 with value: 0.158141968096901.\u001b[0m\n",
            "num_leaves, val_score: 0.158142:  85%|########5 | 17/20 [09:16<01:41, 33.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.126309\tvalid_1's multi_logloss: 0.161659\n",
            "[200]\ttraining's multi_logloss: 0.100574\tvalid_1's multi_logloss: 0.158268\n",
            "Early stopping, best iteration is:\n",
            "[194]\ttraining's multi_logloss: 0.101732\tvalid_1's multi_logloss: 0.158267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158142:  90%|######### | 18/20 [09:49<01:06, 33.45s/it]\u001b[32m[I 2020-10-09 08:19:37,588]\u001b[0m Trial 24 finished with value: 0.15826733655923175 and parameters: {'num_leaves': 138}. Best is trial 13 with value: 0.158141968096901.\u001b[0m\n",
            "num_leaves, val_score: 0.158142:  90%|######### | 18/20 [09:49<01:06, 33.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.12463\tvalid_1's multi_logloss: 0.161911\n",
            "Early stopping, best iteration is:\n",
            "[160]\ttraining's multi_logloss: 0.106963\tvalid_1's multi_logloss: 0.158864\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158142:  95%|#########5| 19/20 [10:17<00:31, 31.94s/it]\u001b[32m[I 2020-10-09 08:20:05,993]\u001b[0m Trial 25 finished with value: 0.15886356750557545 and parameters: {'num_leaves': 146}. Best is trial 13 with value: 0.158141968096901.\u001b[0m\n",
            "num_leaves, val_score: 0.158142:  95%|#########5| 19/20 [10:17<00:31, 31.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.113549\tvalid_1's multi_logloss: 0.161016\n",
            "Early stopping, best iteration is:\n",
            "[173]\ttraining's multi_logloss: 0.0904945\tvalid_1's multi_logloss: 0.158279\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.158142: 100%|##########| 20/20 [10:51<00:00, 32.47s/it]\u001b[32m[I 2020-10-09 08:20:39,699]\u001b[0m Trial 26 finished with value: 0.1582788670122336 and parameters: {'num_leaves': 205}. Best is trial 13 with value: 0.158141968096901.\u001b[0m\n",
            "num_leaves, val_score: 0.158142: 100%|##########| 20/20 [10:51<00:00, 32.57s/it]\n",
            "bagging, val_score: 0.158142:   0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.132101\tvalid_1's multi_logloss: 0.163018\n",
            "[200]\ttraining's multi_logloss: 0.106378\tvalid_1's multi_logloss: 0.159647\n",
            "Early stopping, best iteration is:\n",
            "[196]\ttraining's multi_logloss: 0.107181\tvalid_1's multi_logloss: 0.159581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.158142:  10%|#         | 1/10 [00:35<05:15, 35.01s/it]\u001b[32m[I 2020-10-09 08:21:14,728]\u001b[0m Trial 27 finished with value: 0.15958067326501577 and parameters: {'bagging_fraction': 0.52643611680558, 'bagging_freq': 6}. Best is trial 27 with value: 0.15958067326501577.\u001b[0m\n",
            "bagging, val_score: 0.158142:  10%|#         | 1/10 [00:35<05:15, 35.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.130645\tvalid_1's multi_logloss: 0.162136\n",
            "[200]\ttraining's multi_logloss: 0.105471\tvalid_1's multi_logloss: 0.158344\n",
            "Early stopping, best iteration is:\n",
            "[208]\ttraining's multi_logloss: 0.10397\tvalid_1's multi_logloss: 0.158304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.158142:  20%|##        | 2/10 [01:10<04:40, 35.04s/it]\u001b[32m[I 2020-10-09 08:21:49,819]\u001b[0m Trial 28 finished with value: 0.15830417782382325 and parameters: {'bagging_fraction': 0.9031734842488877, 'bagging_freq': 1}. Best is trial 28 with value: 0.15830417782382325.\u001b[0m\n",
            "bagging, val_score: 0.158142:  20%|##        | 2/10 [01:10<04:40, 35.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.130405\tvalid_1's multi_logloss: 0.162113\n",
            "[200]\ttraining's multi_logloss: 0.105902\tvalid_1's multi_logloss: 0.158209\n",
            "Early stopping, best iteration is:\n",
            "[197]\ttraining's multi_logloss: 0.106396\tvalid_1's multi_logloss: 0.15818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.158142:  30%|###       | 3/10 [01:43<04:01, 34.48s/it]\u001b[32m[I 2020-10-09 08:22:22,990]\u001b[0m Trial 29 finished with value: 0.15818025805575808 and parameters: {'bagging_fraction': 0.9894130001651597, 'bagging_freq': 1}. Best is trial 29 with value: 0.15818025805575808.\u001b[0m\n",
            "bagging, val_score: 0.158142:  30%|###       | 3/10 [01:43<04:01, 34.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.130305\tvalid_1's multi_logloss: 0.16237\n",
            "[200]\ttraining's multi_logloss: 0.105969\tvalid_1's multi_logloss: 0.158735\n",
            "Early stopping, best iteration is:\n",
            "[207]\ttraining's multi_logloss: 0.104699\tvalid_1's multi_logloss: 0.158732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.158142:  40%|####      | 4/10 [02:17<03:26, 34.41s/it]\u001b[32m[I 2020-10-09 08:22:57,251]\u001b[0m Trial 30 finished with value: 0.1587322299575238 and parameters: {'bagging_fraction': 0.9972750882705312, 'bagging_freq': 1}. Best is trial 29 with value: 0.15818025805575808.\u001b[0m\n",
            "bagging, val_score: 0.158142:  40%|####      | 4/10 [02:17<03:26, 34.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.130894\tvalid_1's multi_logloss: 0.162452\n",
            "[200]\ttraining's multi_logloss: 0.105381\tvalid_1's multi_logloss: 0.158627\n",
            "Early stopping, best iteration is:\n",
            "[191]\ttraining's multi_logloss: 0.107142\tvalid_1's multi_logloss: 0.158595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.158142:  50%|#####     | 5/10 [02:56<02:58, 35.63s/it]\u001b[32m[I 2020-10-09 08:23:35,728]\u001b[0m Trial 31 finished with value: 0.15859521595314538 and parameters: {'bagging_fraction': 0.7742633271552806, 'bagging_freq': 3}. Best is trial 29 with value: 0.15818025805575808.\u001b[0m\n",
            "bagging, val_score: 0.158142:  50%|#####     | 5/10 [02:56<02:58, 35.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.132828\tvalid_1's multi_logloss: 0.163238\n",
            "Early stopping, best iteration is:\n",
            "[178]\ttraining's multi_logloss: 0.111253\tvalid_1's multi_logloss: 0.160163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.158142:  60%|######    | 6/10 [03:27<02:17, 34.43s/it]\u001b[32m[I 2020-10-09 08:24:07,337]\u001b[0m Trial 32 finished with value: 0.16016310151877391 and parameters: {'bagging_fraction': 0.4238130585636909, 'bagging_freq': 4}. Best is trial 29 with value: 0.15818025805575808.\u001b[0m\n",
            "bagging, val_score: 0.158142:  60%|######    | 6/10 [03:27<02:17, 34.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.131176\tvalid_1's multi_logloss: 0.162742\n",
            "[200]\ttraining's multi_logloss: 0.105263\tvalid_1's multi_logloss: 0.159274\n",
            "Early stopping, best iteration is:\n",
            "[195]\ttraining's multi_logloss: 0.106233\tvalid_1's multi_logloss: 0.159214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.158142:  70%|#######   | 7/10 [04:05<01:46, 35.37s/it]\u001b[32m[I 2020-10-09 08:24:44,926]\u001b[0m Trial 33 finished with value: 0.1592143589140377 and parameters: {'bagging_fraction': 0.6726566231981269, 'bagging_freq': 3}. Best is trial 29 with value: 0.15818025805575808.\u001b[0m\n",
            "bagging, val_score: 0.158142:  70%|#######   | 7/10 [04:05<01:46, 35.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.130257\tvalid_1's multi_logloss: 0.162441\n",
            "Early stopping, best iteration is:\n",
            "[186]\ttraining's multi_logloss: 0.108188\tvalid_1's multi_logloss: 0.158493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.158142:  80%|########  | 8/10 [04:44<01:12, 36.48s/it]\u001b[32m[I 2020-10-09 08:25:24,003]\u001b[0m Trial 34 finished with value: 0.15849344545423105 and parameters: {'bagging_fraction': 0.9843674044845212, 'bagging_freq': 7}. Best is trial 29 with value: 0.15818025805575808.\u001b[0m\n",
            "bagging, val_score: 0.158142:  80%|########  | 8/10 [04:44<01:12, 36.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.130814\tvalid_1's multi_logloss: 0.162149\n",
            "Early stopping, best iteration is:\n",
            "[183]\ttraining's multi_logloss: 0.10857\tvalid_1's multi_logloss: 0.158469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.158142:  90%|######### | 9/10 [05:15<00:34, 34.87s/it]\u001b[32m[I 2020-10-09 08:25:55,088]\u001b[0m Trial 35 finished with value: 0.15846927782779008 and parameters: {'bagging_fraction': 0.8129574509532146, 'bagging_freq': 1}. Best is trial 29 with value: 0.15818025805575808.\u001b[0m\n",
            "bagging, val_score: 0.158142:  90%|######### | 9/10 [05:15<00:34, 34.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.131251\tvalid_1's multi_logloss: 0.162726\n",
            "Early stopping, best iteration is:\n",
            "[185]\ttraining's multi_logloss: 0.108245\tvalid_1's multi_logloss: 0.158845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.158142: 100%|##########| 10/10 [05:50<00:00, 35.03s/it]\u001b[32m[I 2020-10-09 08:26:30,485]\u001b[0m Trial 36 finished with value: 0.15884526603505497 and parameters: {'bagging_fraction': 0.6638171520401132, 'bagging_freq': 4}. Best is trial 29 with value: 0.15818025805575808.\u001b[0m\n",
            "bagging, val_score: 0.158142: 100%|##########| 10/10 [05:50<00:00, 35.08s/it]\n",
            "feature_fraction_stage2, val_score: 0.158142:   0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.130439\tvalid_1's multi_logloss: 0.161949\n",
            "[200]\ttraining's multi_logloss: 0.106144\tvalid_1's multi_logloss: 0.15817\n",
            "Early stopping, best iteration is:\n",
            "[195]\ttraining's multi_logloss: 0.106949\tvalid_1's multi_logloss: 0.158142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction_stage2, val_score: 0.158142:  33%|###3      | 1/3 [00:37<01:14, 37.46s/it]\u001b[32m[I 2020-10-09 08:27:07,963]\u001b[0m Trial 37 finished with value: 0.158141968096901 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 0.158141968096901.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 0.158142:  33%|###3      | 1/3 [00:37<01:14, 37.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.12873\tvalid_1's multi_logloss: 0.161168\n",
            "[200]\ttraining's multi_logloss: 0.105484\tvalid_1's multi_logloss: 0.158384\n",
            "Early stopping, best iteration is:\n",
            "[191]\ttraining's multi_logloss: 0.107039\tvalid_1's multi_logloss: 0.158371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction_stage2, val_score: 0.158142:  67%|######6   | 2/3 [01:08<00:35, 35.63s/it]\u001b[32m[I 2020-10-09 08:27:39,319]\u001b[0m Trial 38 finished with value: 0.15837079134679016 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.158141968096901.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 0.158142:  67%|######6   | 2/3 [01:08<00:35, 35.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.127827\tvalid_1's multi_logloss: 0.160985\n",
            "Early stopping, best iteration is:\n",
            "[159]\ttraining's multi_logloss: 0.112415\tvalid_1's multi_logloss: 0.1586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction_stage2, val_score: 0.158142: 100%|##########| 3/3 [01:36<00:00, 33.26s/it]\u001b[32m[I 2020-10-09 08:28:07,062]\u001b[0m Trial 39 finished with value: 0.15860046301853503 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.158141968096901.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 0.158142: 100%|##########| 3/3 [01:36<00:00, 32.19s/it]\n",
            "regularization_factors, val_score: 0.158142:   0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.130423\tvalid_1's multi_logloss: 0.16219\n",
            "[200]\ttraining's multi_logloss: 0.106186\tvalid_1's multi_logloss: 0.158585\n",
            "Early stopping, best iteration is:\n",
            "[190]\ttraining's multi_logloss: 0.107894\tvalid_1's multi_logloss: 0.158547\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.158142:   5%|5         | 1/20 [00:30<09:44, 30.75s/it]\u001b[32m[I 2020-10-09 08:28:37,824]\u001b[0m Trial 40 finished with value: 0.15854673805197536 and parameters: {'lambda_l1': 0.013616282965219809, 'lambda_l2': 2.0568953111463953e-07}. Best is trial 40 with value: 0.15854673805197536.\u001b[0m\n",
            "regularization_factors, val_score: 0.158142:   5%|5         | 1/20 [00:30<09:44, 30.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.135759\tvalid_1's multi_logloss: 0.16251\n",
            "[200]\ttraining's multi_logloss: 0.114737\tvalid_1's multi_logloss: 0.158161\n",
            "Early stopping, best iteration is:\n",
            "[256]\ttraining's multi_logloss: 0.10712\tvalid_1's multi_logloss: 0.157949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157949:  10%|#         | 2/20 [01:12<10:15, 34.20s/it]\u001b[32m[I 2020-10-09 08:29:20,054]\u001b[0m Trial 41 finished with value: 0.15794940940398738 and parameters: {'lambda_l1': 1.727667362174989e-08, 'lambda_l2': 6.232406926967285}. Best is trial 41 with value: 0.15794940940398738.\u001b[0m\n",
            "regularization_factors, val_score: 0.157949:  10%|#         | 2/20 [01:12<10:15, 34.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.136266\tvalid_1's multi_logloss: 0.162311\n",
            "[200]\ttraining's multi_logloss: 0.115561\tvalid_1's multi_logloss: 0.157963\n",
            "Early stopping, best iteration is:\n",
            "[239]\ttraining's multi_logloss: 0.110055\tvalid_1's multi_logloss: 0.157746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  15%|#5        | 3/20 [01:52<10:08, 35.81s/it]\u001b[32m[I 2020-10-09 08:29:59,620]\u001b[0m Trial 42 finished with value: 0.1577462159288306 and parameters: {'lambda_l1': 1.6189202148025895e-08, 'lambda_l2': 7.410688264307839}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  15%|#5        | 3/20 [01:52<10:08, 35.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.135242\tvalid_1's multi_logloss: 0.162313\n",
            "[200]\ttraining's multi_logloss: 0.11381\tvalid_1's multi_logloss: 0.158189\n",
            "Early stopping, best iteration is:\n",
            "[206]\ttraining's multi_logloss: 0.112934\tvalid_1's multi_logloss: 0.158144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  20%|##        | 4/20 [02:27<09:26, 35.40s/it]\u001b[32m[I 2020-10-09 08:30:34,075]\u001b[0m Trial 43 finished with value: 0.1581435905258908 and parameters: {'lambda_l1': 2.8718842843752094e-08, 'lambda_l2': 5.133926686379626}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  20%|##        | 4/20 [02:27<09:26, 35.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.137084\tvalid_1's multi_logloss: 0.162645\n",
            "[200]\ttraining's multi_logloss: 0.116978\tvalid_1's multi_logloss: 0.158095\n",
            "Early stopping, best iteration is:\n",
            "[227]\ttraining's multi_logloss: 0.113096\tvalid_1's multi_logloss: 0.157923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  25%|##5       | 5/20 [03:05<09:03, 36.21s/it]\u001b[32m[I 2020-10-09 08:31:12,175]\u001b[0m Trial 44 finished with value: 0.15792337284638505 and parameters: {'lambda_l1': 1.795460098723978e-08, 'lambda_l2': 9.745112985237425}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  25%|##5       | 5/20 [03:05<09:03, 36.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.13624\tvalid_1's multi_logloss: 0.162496\n",
            "[200]\ttraining's multi_logloss: 0.115276\tvalid_1's multi_logloss: 0.157973\n",
            "Early stopping, best iteration is:\n",
            "[226]\ttraining's multi_logloss: 0.111865\tvalid_1's multi_logloss: 0.15788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  30%|###       | 6/20 [03:42<08:32, 36.60s/it]\u001b[32m[I 2020-10-09 08:31:49,702]\u001b[0m Trial 45 finished with value: 0.15787957373371314 and parameters: {'lambda_l1': 1.0431099287542479e-08, 'lambda_l2': 7.423495810946611}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  30%|###       | 6/20 [03:42<08:32, 36.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.136974\tvalid_1's multi_logloss: 0.162608\n",
            "[200]\ttraining's multi_logloss: 0.116661\tvalid_1's multi_logloss: 0.158113\n",
            "Early stopping, best iteration is:\n",
            "[222]\ttraining's multi_logloss: 0.113478\tvalid_1's multi_logloss: 0.158032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  35%|###5      | 7/20 [04:19<07:57, 36.77s/it]\u001b[32m[I 2020-10-09 08:32:26,843]\u001b[0m Trial 46 finished with value: 0.15803236810074697 and parameters: {'lambda_l1': 1.2661714332592246e-08, 'lambda_l2': 9.261844915469576}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  35%|###5      | 7/20 [04:19<07:57, 36.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.13625\tvalid_1's multi_logloss: 0.16242\n",
            "[200]\ttraining's multi_logloss: 0.115169\tvalid_1's multi_logloss: 0.157896\n",
            "Early stopping, best iteration is:\n",
            "[236]\ttraining's multi_logloss: 0.1101\tvalid_1's multi_logloss: 0.157781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  40%|####      | 8/20 [04:58<07:29, 37.44s/it]\u001b[32m[I 2020-10-09 08:33:05,854]\u001b[0m Trial 47 finished with value: 0.15778050746247924 and parameters: {'lambda_l1': 1.1036598871106428e-08, 'lambda_l2': 7.116310285648037}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  40%|####      | 8/20 [04:58<07:29, 37.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.135754\tvalid_1's multi_logloss: 0.162288\n",
            "[200]\ttraining's multi_logloss: 0.114789\tvalid_1's multi_logloss: 0.15802\n",
            "Early stopping, best iteration is:\n",
            "[208]\ttraining's multi_logloss: 0.113684\tvalid_1's multi_logloss: 0.157989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  45%|####5     | 9/20 [05:33<06:42, 36.57s/it]\u001b[32m[I 2020-10-09 08:33:40,382]\u001b[0m Trial 48 finished with value: 0.1579894153522627 and parameters: {'lambda_l1': 1.2446853759197551e-08, 'lambda_l2': 6.251765679701918}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  45%|####5     | 9/20 [05:33<06:42, 36.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.136925\tvalid_1's multi_logloss: 0.162653\n",
            "[200]\ttraining's multi_logloss: 0.116464\tvalid_1's multi_logloss: 0.158039\n",
            "Early stopping, best iteration is:\n",
            "[241]\ttraining's multi_logloss: 0.110911\tvalid_1's multi_logloss: 0.157898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  50%|#####     | 10/20 [06:13<06:16, 37.68s/it]\u001b[32m[I 2020-10-09 08:34:20,665]\u001b[0m Trial 49 finished with value: 0.15789783371559662 and parameters: {'lambda_l1': 1.7384174942526162e-08, 'lambda_l2': 9.143996323086641}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  50%|#####     | 10/20 [06:13<06:16, 37.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.136747\tvalid_1's multi_logloss: 0.162669\n",
            "[200]\ttraining's multi_logloss: 0.116292\tvalid_1's multi_logloss: 0.158301\n",
            "Early stopping, best iteration is:\n",
            "[235]\ttraining's multi_logloss: 0.111415\tvalid_1's multi_logloss: 0.158191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  55%|#####5    | 11/20 [06:52<05:43, 38.15s/it]\u001b[32m[I 2020-10-09 08:34:59,919]\u001b[0m Trial 50 finished with value: 0.15819056922786415 and parameters: {'lambda_l1': 1.0457660972041971e-08, 'lambda_l2': 8.707773931498973}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  55%|#####5    | 11/20 [06:52<05:43, 38.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.136863\tvalid_1's multi_logloss: 0.1626\n",
            "[200]\ttraining's multi_logloss: 0.116187\tvalid_1's multi_logloss: 0.158114\n",
            "Early stopping, best iteration is:\n",
            "[224]\ttraining's multi_logloss: 0.112947\tvalid_1's multi_logloss: 0.157999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  60%|######    | 12/20 [07:30<05:04, 38.04s/it]\u001b[32m[I 2020-10-09 08:35:37,684]\u001b[0m Trial 51 finished with value: 0.15799890793864096 and parameters: {'lambda_l1': 2.034539024325042e-08, 'lambda_l2': 8.824976654549125}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  60%|######    | 12/20 [07:30<05:04, 38.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.137076\tvalid_1's multi_logloss: 0.162636\n",
            "[200]\ttraining's multi_logloss: 0.116763\tvalid_1's multi_logloss: 0.158124\n",
            "Early stopping, best iteration is:\n",
            "[240]\ttraining's multi_logloss: 0.111468\tvalid_1's multi_logloss: 0.157952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  65%|######5   | 13/20 [08:10<04:30, 38.59s/it]\u001b[32m[I 2020-10-09 08:36:17,575]\u001b[0m Trial 52 finished with value: 0.15795176642230088 and parameters: {'lambda_l1': 6.336539908812146e-08, 'lambda_l2': 9.832193379561723}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  65%|######5   | 13/20 [08:10<04:30, 38.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.13085\tvalid_1's multi_logloss: 0.162503\n",
            "[200]\ttraining's multi_logloss: 0.106697\tvalid_1's multi_logloss: 0.158505\n",
            "Early stopping, best iteration is:\n",
            "[195]\ttraining's multi_logloss: 0.107564\tvalid_1's multi_logloss: 0.158476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  70%|#######   | 14/20 [08:48<03:50, 38.36s/it]\u001b[32m[I 2020-10-09 08:36:55,381]\u001b[0m Trial 53 finished with value: 0.1584755709710293 and parameters: {'lambda_l1': 4.93158381616147e-06, 'lambda_l2': 0.14220036595469923}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  70%|#######   | 14/20 [08:48<03:50, 38.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.130846\tvalid_1's multi_logloss: 0.162293\n",
            "[200]\ttraining's multi_logloss: 0.106786\tvalid_1's multi_logloss: 0.158349\n",
            "Early stopping, best iteration is:\n",
            "[200]\ttraining's multi_logloss: 0.106786\tvalid_1's multi_logloss: 0.158349\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  75%|#######5  | 15/20 [09:20<03:02, 36.57s/it]\u001b[32m[I 2020-10-09 08:37:27,770]\u001b[0m Trial 54 finished with value: 0.15834943388714173 and parameters: {'lambda_l1': 5.127735054661721e-07, 'lambda_l2': 0.13726002788005398}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  75%|#######5  | 15/20 [09:20<03:02, 36.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.131067\tvalid_1's multi_logloss: 0.162326\n",
            "[200]\ttraining's multi_logloss: 0.107066\tvalid_1's multi_logloss: 0.158705\n",
            "Early stopping, best iteration is:\n",
            "[208]\ttraining's multi_logloss: 0.105729\tvalid_1's multi_logloss: 0.158683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  80%|########  | 16/20 [09:54<02:22, 35.68s/it]\u001b[32m[I 2020-10-09 08:38:01,390]\u001b[0m Trial 55 finished with value: 0.15868321936405258 and parameters: {'lambda_l1': 1.0651797636672062e-08, 'lambda_l2': 0.2461670900977588}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  80%|########  | 16/20 [09:54<02:22, 35.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.131731\tvalid_1's multi_logloss: 0.162073\n",
            "[200]\ttraining's multi_logloss: 0.108275\tvalid_1's multi_logloss: 0.158244\n",
            "Early stopping, best iteration is:\n",
            "[215]\ttraining's multi_logloss: 0.105879\tvalid_1's multi_logloss: 0.15821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  85%|########5 | 17/20 [10:29<01:46, 35.44s/it]\u001b[32m[I 2020-10-09 08:38:36,247]\u001b[0m Trial 56 finished with value: 0.15821012848666574 and parameters: {'lambda_l1': 2.6078350557654763e-07, 'lambda_l2': 0.6585398556266522}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  85%|########5 | 17/20 [10:29<01:46, 35.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.141281\tvalid_1's multi_logloss: 0.163416\n",
            "[200]\ttraining's multi_logloss: 0.123028\tvalid_1's multi_logloss: 0.158597\n",
            "Early stopping, best iteration is:\n",
            "[253]\ttraining's multi_logloss: 0.116961\tvalid_1's multi_logloss: 0.158329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  90%|######### | 18/20 [11:10<01:14, 37.24s/it]\u001b[32m[I 2020-10-09 08:39:17,703]\u001b[0m Trial 57 finished with value: 0.15832926052992072 and parameters: {'lambda_l1': 5.712111090905114, 'lambda_l2': 1.5789109482198769}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  90%|######### | 18/20 [11:10<01:14, 37.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.130302\tvalid_1's multi_logloss: 0.162148\n",
            "[200]\ttraining's multi_logloss: 0.106161\tvalid_1's multi_logloss: 0.158158\n",
            "Early stopping, best iteration is:\n",
            "[200]\ttraining's multi_logloss: 0.106161\tvalid_1's multi_logloss: 0.158158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746:  95%|#########5| 19/20 [11:42<00:35, 35.71s/it]\u001b[32m[I 2020-10-09 08:39:49,826]\u001b[0m Trial 58 finished with value: 0.15815792201509293 and parameters: {'lambda_l1': 3.8967442486900903e-07, 'lambda_l2': 0.0007562460919355552}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746:  95%|#########5| 19/20 [11:42<00:35, 35.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.132644\tvalid_1's multi_logloss: 0.162212\n",
            "[200]\ttraining's multi_logloss: 0.109781\tvalid_1's multi_logloss: 0.158277\n",
            "Early stopping, best iteration is:\n",
            "[198]\ttraining's multi_logloss: 0.110123\tvalid_1's multi_logloss: 0.158247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.157746: 100%|##########| 20/20 [12:15<00:00, 34.69s/it]\u001b[32m[I 2020-10-09 08:40:22,160]\u001b[0m Trial 59 finished with value: 0.15824715432984193 and parameters: {'lambda_l1': 1.1266702887109443e-08, 'lambda_l2': 1.3519542834313254}. Best is trial 42 with value: 0.1577462159288306.\u001b[0m\n",
            "regularization_factors, val_score: 0.157746: 100%|##########| 20/20 [12:15<00:00, 36.75s/it]\n",
            "min_data_in_leaf, val_score: 0.157746:   0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.136028\tvalid_1's multi_logloss: 0.162345\n",
            "[200]\ttraining's multi_logloss: 0.115534\tvalid_1's multi_logloss: 0.158008\n",
            "Early stopping, best iteration is:\n",
            "[211]\ttraining's multi_logloss: 0.114013\tvalid_1's multi_logloss: 0.157949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 0.157746:  20%|##        | 1/5 [00:35<02:23, 35.87s/it]\u001b[32m[I 2020-10-09 08:40:58,037]\u001b[0m Trial 60 finished with value: 0.15794897374420866 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.15794897374420866.\u001b[0m\n",
            "min_data_in_leaf, val_score: 0.157746:  20%|##        | 1/5 [00:35<02:23, 35.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.136302\tvalid_1's multi_logloss: 0.162482\n",
            "[200]\ttraining's multi_logloss: 0.115721\tvalid_1's multi_logloss: 0.158311\n",
            "Early stopping, best iteration is:\n",
            "[225]\ttraining's multi_logloss: 0.112235\tvalid_1's multi_logloss: 0.158227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 0.157746:  40%|####      | 2/5 [01:13<01:49, 36.36s/it]\u001b[32m[I 2020-10-09 08:41:35,563]\u001b[0m Trial 61 finished with value: 0.15822685882301118 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.15794897374420866.\u001b[0m\n",
            "min_data_in_leaf, val_score: 0.157746:  40%|####      | 2/5 [01:13<01:49, 36.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.13617\tvalid_1's multi_logloss: 0.162458\n",
            "[200]\ttraining's multi_logloss: 0.115619\tvalid_1's multi_logloss: 0.158072\n",
            "Early stopping, best iteration is:\n",
            "[202]\ttraining's multi_logloss: 0.115332\tvalid_1's multi_logloss: 0.158031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 0.157746:  60%|######    | 3/5 [01:47<01:11, 35.67s/it]\u001b[32m[I 2020-10-09 08:42:09,603]\u001b[0m Trial 62 finished with value: 0.15803075608344988 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.15794897374420866.\u001b[0m\n",
            "min_data_in_leaf, val_score: 0.157746:  60%|######    | 3/5 [01:47<01:11, 35.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.137242\tvalid_1's multi_logloss: 0.162549\n",
            "[200]\ttraining's multi_logloss: 0.116483\tvalid_1's multi_logloss: 0.158065\n",
            "Early stopping, best iteration is:\n",
            "[252]\ttraining's multi_logloss: 0.109314\tvalid_1's multi_logloss: 0.157822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 0.157746:  80%|########  | 4/5 [02:29<00:37, 37.65s/it]\u001b[32m[I 2020-10-09 08:42:51,871]\u001b[0m Trial 63 finished with value: 0.15782232653626724 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.15782232653626724.\u001b[0m\n",
            "min_data_in_leaf, val_score: 0.157746:  80%|########  | 4/5 [02:29<00:37, 37.65s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.136739\tvalid_1's multi_logloss: 0.162716\n",
            "[200]\ttraining's multi_logloss: 0.115821\tvalid_1's multi_logloss: 0.158294\n",
            "Early stopping, best iteration is:\n",
            "[219]\ttraining's multi_logloss: 0.113112\tvalid_1's multi_logloss: 0.1582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 0.157746: 100%|##########| 5/5 [03:06<00:00, 37.27s/it]\u001b[32m[I 2020-10-09 08:43:28,274]\u001b[0m Trial 64 finished with value: 0.15820036984736158 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.15782232653626724.\u001b[0m\n",
            "min_data_in_leaf, val_score: 0.157746: 100%|##########| 5/5 [03:06<00:00, 37.22s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best params: {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': 3, 'lambda_l1': 1.6189202148025895e-08, 'lambda_l2': 7.410688264307839, 'random_state': 42, 'n_jobs': -1, 'feature_pre_filter': False, 'bagging_freq': 1, 'num_leaves': 119, 'feature_fraction': 0.4, 'bagging_fraction': 1.0, 'min_child_samples': 20}\n",
            "  Accuracy = 0.93365625\n",
            "  Params: \n",
            "    objective: multiclass\n",
            "    metric: multi_logloss\n",
            "    num_class: 3\n",
            "    lambda_l1: 1.6189202148025895e-08\n",
            "    lambda_l2: 7.410688264307839\n",
            "    random_state: 42\n",
            "    n_jobs: -1\n",
            "    feature_pre_filter: False\n",
            "    bagging_freq: 1\n",
            "    num_leaves: 119\n",
            "    feature_fraction: 0.4\n",
            "    bagging_fraction: 1.0\n",
            "    min_child_samples: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYbjY_b5tjrA"
      },
      "source": [
        "## Stratified K-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:51:30.898328Z",
          "start_time": "2020-10-05T08:51:30.838172Z"
        },
        "id": "F4tAX9pftjrA"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOMf08RmtjrC"
      },
      "source": [
        "## LightGBM 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:54:00.359900Z",
          "start_time": "2020-10-05T08:53:24.061986Z"
        },
        "scrolled": true,
        "id": "9P5kPi0stjrC",
        "outputId": "35d96b29-e9ef-4db6-d4f1-c8f835ca2023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "p_val = np.zeros((trn.shape[0], n_class))\n",
        "p_tst = np.zeros((tst.shape[0], n_class))\n",
        "for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
        "    print(f'training model for CV #{i}')\n",
        "    clf = LGBMClassifier(**params)\n",
        "    clf.fit(trn[i_trn], y[i_trn],\n",
        "            eval_set=[(trn[i_val], y[i_val])],\n",
        "            eval_metric='multiclass',\n",
        "            early_stopping_rounds=10\n",
        "            )\n",
        "    \n",
        "    p_val[i_val, :] = clf.predict_proba(trn[i_val])\n",
        "    p_tst += clf.predict_proba(tst) / n_fold"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training model for CV #1\n",
            "[1]\tvalid_0's multi_logloss: 0.879971\tvalid_0's multi_logloss: 0.879971\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's multi_logloss: 0.79408\tvalid_0's multi_logloss: 0.79408\n",
            "[3]\tvalid_0's multi_logloss: 0.720777\tvalid_0's multi_logloss: 0.720777\n",
            "[4]\tvalid_0's multi_logloss: 0.661654\tvalid_0's multi_logloss: 0.661654\n",
            "[5]\tvalid_0's multi_logloss: 0.607757\tvalid_0's multi_logloss: 0.607757\n",
            "[6]\tvalid_0's multi_logloss: 0.5641\tvalid_0's multi_logloss: 0.5641\n",
            "[7]\tvalid_0's multi_logloss: 0.523582\tvalid_0's multi_logloss: 0.523582\n",
            "[8]\tvalid_0's multi_logloss: 0.489913\tvalid_0's multi_logloss: 0.489913\n",
            "[9]\tvalid_0's multi_logloss: 0.456677\tvalid_0's multi_logloss: 0.456677\n",
            "[10]\tvalid_0's multi_logloss: 0.430618\tvalid_0's multi_logloss: 0.430618\n",
            "[11]\tvalid_0's multi_logloss: 0.40615\tvalid_0's multi_logloss: 0.40615\n",
            "[12]\tvalid_0's multi_logloss: 0.381702\tvalid_0's multi_logloss: 0.381702\n",
            "[13]\tvalid_0's multi_logloss: 0.363139\tvalid_0's multi_logloss: 0.363139\n",
            "[14]\tvalid_0's multi_logloss: 0.344196\tvalid_0's multi_logloss: 0.344196\n",
            "[15]\tvalid_0's multi_logloss: 0.329671\tvalid_0's multi_logloss: 0.329671\n",
            "[16]\tvalid_0's multi_logloss: 0.314475\tvalid_0's multi_logloss: 0.314475\n",
            "[17]\tvalid_0's multi_logloss: 0.300192\tvalid_0's multi_logloss: 0.300192\n",
            "[18]\tvalid_0's multi_logloss: 0.288969\tvalid_0's multi_logloss: 0.288969\n",
            "[19]\tvalid_0's multi_logloss: 0.277973\tvalid_0's multi_logloss: 0.277973\n",
            "[20]\tvalid_0's multi_logloss: 0.268637\tvalid_0's multi_logloss: 0.268637\n",
            "[21]\tvalid_0's multi_logloss: 0.259462\tvalid_0's multi_logloss: 0.259462\n",
            "[22]\tvalid_0's multi_logloss: 0.251634\tvalid_0's multi_logloss: 0.251634\n",
            "[23]\tvalid_0's multi_logloss: 0.243192\tvalid_0's multi_logloss: 0.243192\n",
            "[24]\tvalid_0's multi_logloss: 0.236086\tvalid_0's multi_logloss: 0.236086\n",
            "[25]\tvalid_0's multi_logloss: 0.229928\tvalid_0's multi_logloss: 0.229928\n",
            "[26]\tvalid_0's multi_logloss: 0.223739\tvalid_0's multi_logloss: 0.223739\n",
            "[27]\tvalid_0's multi_logloss: 0.218545\tvalid_0's multi_logloss: 0.218545\n",
            "[28]\tvalid_0's multi_logloss: 0.214206\tvalid_0's multi_logloss: 0.214206\n",
            "[29]\tvalid_0's multi_logloss: 0.209407\tvalid_0's multi_logloss: 0.209407\n",
            "[30]\tvalid_0's multi_logloss: 0.205945\tvalid_0's multi_logloss: 0.205945\n",
            "[31]\tvalid_0's multi_logloss: 0.202602\tvalid_0's multi_logloss: 0.202602\n",
            "[32]\tvalid_0's multi_logloss: 0.198949\tvalid_0's multi_logloss: 0.198949\n",
            "[33]\tvalid_0's multi_logloss: 0.196054\tvalid_0's multi_logloss: 0.196054\n",
            "[34]\tvalid_0's multi_logloss: 0.192881\tvalid_0's multi_logloss: 0.192881\n",
            "[35]\tvalid_0's multi_logloss: 0.190217\tvalid_0's multi_logloss: 0.190217\n",
            "[36]\tvalid_0's multi_logloss: 0.188064\tvalid_0's multi_logloss: 0.188064\n",
            "[37]\tvalid_0's multi_logloss: 0.185662\tvalid_0's multi_logloss: 0.185662\n",
            "[38]\tvalid_0's multi_logloss: 0.183728\tvalid_0's multi_logloss: 0.183728\n",
            "[39]\tvalid_0's multi_logloss: 0.181756\tvalid_0's multi_logloss: 0.181756\n",
            "[40]\tvalid_0's multi_logloss: 0.179867\tvalid_0's multi_logloss: 0.179867\n",
            "[41]\tvalid_0's multi_logloss: 0.17818\tvalid_0's multi_logloss: 0.17818\n",
            "[42]\tvalid_0's multi_logloss: 0.176913\tvalid_0's multi_logloss: 0.176913\n",
            "[43]\tvalid_0's multi_logloss: 0.17564\tvalid_0's multi_logloss: 0.17564\n",
            "[44]\tvalid_0's multi_logloss: 0.174458\tvalid_0's multi_logloss: 0.174458\n",
            "[45]\tvalid_0's multi_logloss: 0.173176\tvalid_0's multi_logloss: 0.173176\n",
            "[46]\tvalid_0's multi_logloss: 0.172155\tvalid_0's multi_logloss: 0.172155\n",
            "[47]\tvalid_0's multi_logloss: 0.171174\tvalid_0's multi_logloss: 0.171174\n",
            "[48]\tvalid_0's multi_logloss: 0.170534\tvalid_0's multi_logloss: 0.170534\n",
            "[49]\tvalid_0's multi_logloss: 0.169756\tvalid_0's multi_logloss: 0.169756\n",
            "[50]\tvalid_0's multi_logloss: 0.168934\tvalid_0's multi_logloss: 0.168934\n",
            "[51]\tvalid_0's multi_logloss: 0.168251\tvalid_0's multi_logloss: 0.168251\n",
            "[52]\tvalid_0's multi_logloss: 0.167538\tvalid_0's multi_logloss: 0.167538\n",
            "[53]\tvalid_0's multi_logloss: 0.166841\tvalid_0's multi_logloss: 0.166841\n",
            "[54]\tvalid_0's multi_logloss: 0.166322\tvalid_0's multi_logloss: 0.166322\n",
            "[55]\tvalid_0's multi_logloss: 0.165929\tvalid_0's multi_logloss: 0.165929\n",
            "[56]\tvalid_0's multi_logloss: 0.165411\tvalid_0's multi_logloss: 0.165411\n",
            "[57]\tvalid_0's multi_logloss: 0.165117\tvalid_0's multi_logloss: 0.165117\n",
            "[58]\tvalid_0's multi_logloss: 0.164542\tvalid_0's multi_logloss: 0.164542\n",
            "[59]\tvalid_0's multi_logloss: 0.164026\tvalid_0's multi_logloss: 0.164026\n",
            "[60]\tvalid_0's multi_logloss: 0.163727\tvalid_0's multi_logloss: 0.163727\n",
            "[61]\tvalid_0's multi_logloss: 0.163521\tvalid_0's multi_logloss: 0.163521\n",
            "[62]\tvalid_0's multi_logloss: 0.163137\tvalid_0's multi_logloss: 0.163137\n",
            "[63]\tvalid_0's multi_logloss: 0.162693\tvalid_0's multi_logloss: 0.162693\n",
            "[64]\tvalid_0's multi_logloss: 0.162343\tvalid_0's multi_logloss: 0.162343\n",
            "[65]\tvalid_0's multi_logloss: 0.16205\tvalid_0's multi_logloss: 0.16205\n",
            "[66]\tvalid_0's multi_logloss: 0.161844\tvalid_0's multi_logloss: 0.161844\n",
            "[67]\tvalid_0's multi_logloss: 0.161566\tvalid_0's multi_logloss: 0.161566\n",
            "[68]\tvalid_0's multi_logloss: 0.161334\tvalid_0's multi_logloss: 0.161334\n",
            "[69]\tvalid_0's multi_logloss: 0.161122\tvalid_0's multi_logloss: 0.161122\n",
            "[70]\tvalid_0's multi_logloss: 0.160775\tvalid_0's multi_logloss: 0.160775\n",
            "[71]\tvalid_0's multi_logloss: 0.16057\tvalid_0's multi_logloss: 0.16057\n",
            "[72]\tvalid_0's multi_logloss: 0.160301\tvalid_0's multi_logloss: 0.160301\n",
            "[73]\tvalid_0's multi_logloss: 0.160126\tvalid_0's multi_logloss: 0.160126\n",
            "[74]\tvalid_0's multi_logloss: 0.159957\tvalid_0's multi_logloss: 0.159957\n",
            "[75]\tvalid_0's multi_logloss: 0.159814\tvalid_0's multi_logloss: 0.159814\n",
            "[76]\tvalid_0's multi_logloss: 0.159608\tvalid_0's multi_logloss: 0.159608\n",
            "[77]\tvalid_0's multi_logloss: 0.159391\tvalid_0's multi_logloss: 0.159391\n",
            "[78]\tvalid_0's multi_logloss: 0.159272\tvalid_0's multi_logloss: 0.159272\n",
            "[79]\tvalid_0's multi_logloss: 0.159184\tvalid_0's multi_logloss: 0.159184\n",
            "[80]\tvalid_0's multi_logloss: 0.159027\tvalid_0's multi_logloss: 0.159027\n",
            "[81]\tvalid_0's multi_logloss: 0.158888\tvalid_0's multi_logloss: 0.158888\n",
            "[82]\tvalid_0's multi_logloss: 0.158763\tvalid_0's multi_logloss: 0.158763\n",
            "[83]\tvalid_0's multi_logloss: 0.158629\tvalid_0's multi_logloss: 0.158629\n",
            "[84]\tvalid_0's multi_logloss: 0.158567\tvalid_0's multi_logloss: 0.158567\n",
            "[85]\tvalid_0's multi_logloss: 0.158461\tvalid_0's multi_logloss: 0.158461\n",
            "[86]\tvalid_0's multi_logloss: 0.15832\tvalid_0's multi_logloss: 0.15832\n",
            "[87]\tvalid_0's multi_logloss: 0.158231\tvalid_0's multi_logloss: 0.158231\n",
            "[88]\tvalid_0's multi_logloss: 0.158107\tvalid_0's multi_logloss: 0.158107\n",
            "[89]\tvalid_0's multi_logloss: 0.157941\tvalid_0's multi_logloss: 0.157941\n",
            "[90]\tvalid_0's multi_logloss: 0.157858\tvalid_0's multi_logloss: 0.157858\n",
            "[91]\tvalid_0's multi_logloss: 0.15776\tvalid_0's multi_logloss: 0.15776\n",
            "[92]\tvalid_0's multi_logloss: 0.157641\tvalid_0's multi_logloss: 0.157641\n",
            "[93]\tvalid_0's multi_logloss: 0.157582\tvalid_0's multi_logloss: 0.157582\n",
            "[94]\tvalid_0's multi_logloss: 0.157494\tvalid_0's multi_logloss: 0.157494\n",
            "[95]\tvalid_0's multi_logloss: 0.157438\tvalid_0's multi_logloss: 0.157438\n",
            "[96]\tvalid_0's multi_logloss: 0.157432\tvalid_0's multi_logloss: 0.157432\n",
            "[97]\tvalid_0's multi_logloss: 0.157367\tvalid_0's multi_logloss: 0.157367\n",
            "[98]\tvalid_0's multi_logloss: 0.157366\tvalid_0's multi_logloss: 0.157366\n",
            "[99]\tvalid_0's multi_logloss: 0.157291\tvalid_0's multi_logloss: 0.157291\n",
            "[100]\tvalid_0's multi_logloss: 0.15725\tvalid_0's multi_logloss: 0.15725\n",
            "[101]\tvalid_0's multi_logloss: 0.157239\tvalid_0's multi_logloss: 0.157239\n",
            "[102]\tvalid_0's multi_logloss: 0.157228\tvalid_0's multi_logloss: 0.157228\n",
            "[103]\tvalid_0's multi_logloss: 0.157209\tvalid_0's multi_logloss: 0.157209\n",
            "[104]\tvalid_0's multi_logloss: 0.157185\tvalid_0's multi_logloss: 0.157185\n",
            "[105]\tvalid_0's multi_logloss: 0.15712\tvalid_0's multi_logloss: 0.15712\n",
            "[106]\tvalid_0's multi_logloss: 0.157127\tvalid_0's multi_logloss: 0.157127\n",
            "[107]\tvalid_0's multi_logloss: 0.157143\tvalid_0's multi_logloss: 0.157143\n",
            "[108]\tvalid_0's multi_logloss: 0.157087\tvalid_0's multi_logloss: 0.157087\n",
            "[109]\tvalid_0's multi_logloss: 0.157095\tvalid_0's multi_logloss: 0.157095\n",
            "[110]\tvalid_0's multi_logloss: 0.157067\tvalid_0's multi_logloss: 0.157067\n",
            "[111]\tvalid_0's multi_logloss: 0.157028\tvalid_0's multi_logloss: 0.157028\n",
            "[112]\tvalid_0's multi_logloss: 0.157034\tvalid_0's multi_logloss: 0.157034\n",
            "[113]\tvalid_0's multi_logloss: 0.156999\tvalid_0's multi_logloss: 0.156999\n",
            "[114]\tvalid_0's multi_logloss: 0.156962\tvalid_0's multi_logloss: 0.156962\n",
            "[115]\tvalid_0's multi_logloss: 0.156961\tvalid_0's multi_logloss: 0.156961\n",
            "[116]\tvalid_0's multi_logloss: 0.156959\tvalid_0's multi_logloss: 0.156959\n",
            "[117]\tvalid_0's multi_logloss: 0.156942\tvalid_0's multi_logloss: 0.156942\n",
            "[118]\tvalid_0's multi_logloss: 0.156938\tvalid_0's multi_logloss: 0.156938\n",
            "[119]\tvalid_0's multi_logloss: 0.156895\tvalid_0's multi_logloss: 0.156895\n",
            "[120]\tvalid_0's multi_logloss: 0.156883\tvalid_0's multi_logloss: 0.156883\n",
            "[121]\tvalid_0's multi_logloss: 0.156878\tvalid_0's multi_logloss: 0.156878\n",
            "[122]\tvalid_0's multi_logloss: 0.156865\tvalid_0's multi_logloss: 0.156865\n",
            "[123]\tvalid_0's multi_logloss: 0.156865\tvalid_0's multi_logloss: 0.156865\n",
            "[124]\tvalid_0's multi_logloss: 0.15691\tvalid_0's multi_logloss: 0.15691\n",
            "[125]\tvalid_0's multi_logloss: 0.156926\tvalid_0's multi_logloss: 0.156926\n",
            "[126]\tvalid_0's multi_logloss: 0.156919\tvalid_0's multi_logloss: 0.156919\n",
            "[127]\tvalid_0's multi_logloss: 0.156925\tvalid_0's multi_logloss: 0.156925\n",
            "[128]\tvalid_0's multi_logloss: 0.156922\tvalid_0's multi_logloss: 0.156922\n",
            "[129]\tvalid_0's multi_logloss: 0.156932\tvalid_0's multi_logloss: 0.156932\n",
            "[130]\tvalid_0's multi_logloss: 0.156952\tvalid_0's multi_logloss: 0.156952\n",
            "[131]\tvalid_0's multi_logloss: 0.156914\tvalid_0's multi_logloss: 0.156914\n",
            "[132]\tvalid_0's multi_logloss: 0.156899\tvalid_0's multi_logloss: 0.156899\n",
            "[133]\tvalid_0's multi_logloss: 0.156905\tvalid_0's multi_logloss: 0.156905\n",
            "Early stopping, best iteration is:\n",
            "[123]\tvalid_0's multi_logloss: 0.156865\tvalid_0's multi_logloss: 0.156865\n",
            "training model for CV #2\n",
            "[1]\tvalid_0's multi_logloss: 0.880254\tvalid_0's multi_logloss: 0.880254\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's multi_logloss: 0.794461\tvalid_0's multi_logloss: 0.794461\n",
            "[3]\tvalid_0's multi_logloss: 0.721285\tvalid_0's multi_logloss: 0.721285\n",
            "[4]\tvalid_0's multi_logloss: 0.662159\tvalid_0's multi_logloss: 0.662159\n",
            "[5]\tvalid_0's multi_logloss: 0.608266\tvalid_0's multi_logloss: 0.608266\n",
            "[6]\tvalid_0's multi_logloss: 0.564985\tvalid_0's multi_logloss: 0.564985\n",
            "[7]\tvalid_0's multi_logloss: 0.524571\tvalid_0's multi_logloss: 0.524571\n",
            "[8]\tvalid_0's multi_logloss: 0.490949\tvalid_0's multi_logloss: 0.490949\n",
            "[9]\tvalid_0's multi_logloss: 0.457837\tvalid_0's multi_logloss: 0.457837\n",
            "[10]\tvalid_0's multi_logloss: 0.431831\tvalid_0's multi_logloss: 0.431831\n",
            "[11]\tvalid_0's multi_logloss: 0.407491\tvalid_0's multi_logloss: 0.407491\n",
            "[12]\tvalid_0's multi_logloss: 0.383007\tvalid_0's multi_logloss: 0.383007\n",
            "[13]\tvalid_0's multi_logloss: 0.364472\tvalid_0's multi_logloss: 0.364472\n",
            "[14]\tvalid_0's multi_logloss: 0.345632\tvalid_0's multi_logloss: 0.345632\n",
            "[15]\tvalid_0's multi_logloss: 0.331148\tvalid_0's multi_logloss: 0.331148\n",
            "[16]\tvalid_0's multi_logloss: 0.316009\tvalid_0's multi_logloss: 0.316009\n",
            "[17]\tvalid_0's multi_logloss: 0.301611\tvalid_0's multi_logloss: 0.301611\n",
            "[18]\tvalid_0's multi_logloss: 0.29037\tvalid_0's multi_logloss: 0.29037\n",
            "[19]\tvalid_0's multi_logloss: 0.279365\tvalid_0's multi_logloss: 0.279365\n",
            "[20]\tvalid_0's multi_logloss: 0.270071\tvalid_0's multi_logloss: 0.270071\n",
            "[21]\tvalid_0's multi_logloss: 0.260878\tvalid_0's multi_logloss: 0.260878\n",
            "[22]\tvalid_0's multi_logloss: 0.253033\tvalid_0's multi_logloss: 0.253033\n",
            "[23]\tvalid_0's multi_logloss: 0.244735\tvalid_0's multi_logloss: 0.244735\n",
            "[24]\tvalid_0's multi_logloss: 0.237755\tvalid_0's multi_logloss: 0.237755\n",
            "[25]\tvalid_0's multi_logloss: 0.231584\tvalid_0's multi_logloss: 0.231584\n",
            "[26]\tvalid_0's multi_logloss: 0.225457\tvalid_0's multi_logloss: 0.225457\n",
            "[27]\tvalid_0's multi_logloss: 0.220281\tvalid_0's multi_logloss: 0.220281\n",
            "[28]\tvalid_0's multi_logloss: 0.215835\tvalid_0's multi_logloss: 0.215835\n",
            "[29]\tvalid_0's multi_logloss: 0.21112\tvalid_0's multi_logloss: 0.21112\n",
            "[30]\tvalid_0's multi_logloss: 0.20764\tvalid_0's multi_logloss: 0.20764\n",
            "[31]\tvalid_0's multi_logloss: 0.204298\tvalid_0's multi_logloss: 0.204298\n",
            "[32]\tvalid_0's multi_logloss: 0.200563\tvalid_0's multi_logloss: 0.200563\n",
            "[33]\tvalid_0's multi_logloss: 0.197626\tvalid_0's multi_logloss: 0.197626\n",
            "[34]\tvalid_0's multi_logloss: 0.194397\tvalid_0's multi_logloss: 0.194397\n",
            "[35]\tvalid_0's multi_logloss: 0.191804\tvalid_0's multi_logloss: 0.191804\n",
            "[36]\tvalid_0's multi_logloss: 0.189713\tvalid_0's multi_logloss: 0.189713\n",
            "[37]\tvalid_0's multi_logloss: 0.187112\tvalid_0's multi_logloss: 0.187112\n",
            "[38]\tvalid_0's multi_logloss: 0.185079\tvalid_0's multi_logloss: 0.185079\n",
            "[39]\tvalid_0's multi_logloss: 0.183131\tvalid_0's multi_logloss: 0.183131\n",
            "[40]\tvalid_0's multi_logloss: 0.181175\tvalid_0's multi_logloss: 0.181175\n",
            "[41]\tvalid_0's multi_logloss: 0.179448\tvalid_0's multi_logloss: 0.179448\n",
            "[42]\tvalid_0's multi_logloss: 0.17818\tvalid_0's multi_logloss: 0.17818\n",
            "[43]\tvalid_0's multi_logloss: 0.176767\tvalid_0's multi_logloss: 0.176767\n",
            "[44]\tvalid_0's multi_logloss: 0.175608\tvalid_0's multi_logloss: 0.175608\n",
            "[45]\tvalid_0's multi_logloss: 0.174331\tvalid_0's multi_logloss: 0.174331\n",
            "[46]\tvalid_0's multi_logloss: 0.17328\tvalid_0's multi_logloss: 0.17328\n",
            "[47]\tvalid_0's multi_logloss: 0.17233\tvalid_0's multi_logloss: 0.17233\n",
            "[48]\tvalid_0's multi_logloss: 0.171688\tvalid_0's multi_logloss: 0.171688\n",
            "[49]\tvalid_0's multi_logloss: 0.170851\tvalid_0's multi_logloss: 0.170851\n",
            "[50]\tvalid_0's multi_logloss: 0.170029\tvalid_0's multi_logloss: 0.170029\n",
            "[51]\tvalid_0's multi_logloss: 0.169312\tvalid_0's multi_logloss: 0.169312\n",
            "[52]\tvalid_0's multi_logloss: 0.168519\tvalid_0's multi_logloss: 0.168519\n",
            "[53]\tvalid_0's multi_logloss: 0.167738\tvalid_0's multi_logloss: 0.167738\n",
            "[54]\tvalid_0's multi_logloss: 0.167158\tvalid_0's multi_logloss: 0.167158\n",
            "[55]\tvalid_0's multi_logloss: 0.166764\tvalid_0's multi_logloss: 0.166764\n",
            "[56]\tvalid_0's multi_logloss: 0.166261\tvalid_0's multi_logloss: 0.166261\n",
            "[57]\tvalid_0's multi_logloss: 0.165995\tvalid_0's multi_logloss: 0.165995\n",
            "[58]\tvalid_0's multi_logloss: 0.165399\tvalid_0's multi_logloss: 0.165399\n",
            "[59]\tvalid_0's multi_logloss: 0.164923\tvalid_0's multi_logloss: 0.164923\n",
            "[60]\tvalid_0's multi_logloss: 0.164626\tvalid_0's multi_logloss: 0.164626\n",
            "[61]\tvalid_0's multi_logloss: 0.164344\tvalid_0's multi_logloss: 0.164344\n",
            "[62]\tvalid_0's multi_logloss: 0.163959\tvalid_0's multi_logloss: 0.163959\n",
            "[63]\tvalid_0's multi_logloss: 0.163462\tvalid_0's multi_logloss: 0.163462\n",
            "[64]\tvalid_0's multi_logloss: 0.163065\tvalid_0's multi_logloss: 0.163065\n",
            "[65]\tvalid_0's multi_logloss: 0.162815\tvalid_0's multi_logloss: 0.162815\n",
            "[66]\tvalid_0's multi_logloss: 0.162606\tvalid_0's multi_logloss: 0.162606\n",
            "[67]\tvalid_0's multi_logloss: 0.16227\tvalid_0's multi_logloss: 0.16227\n",
            "[68]\tvalid_0's multi_logloss: 0.162027\tvalid_0's multi_logloss: 0.162027\n",
            "[69]\tvalid_0's multi_logloss: 0.161825\tvalid_0's multi_logloss: 0.161825\n",
            "[70]\tvalid_0's multi_logloss: 0.161539\tvalid_0's multi_logloss: 0.161539\n",
            "[71]\tvalid_0's multi_logloss: 0.16138\tvalid_0's multi_logloss: 0.16138\n",
            "[72]\tvalid_0's multi_logloss: 0.161069\tvalid_0's multi_logloss: 0.161069\n",
            "[73]\tvalid_0's multi_logloss: 0.160921\tvalid_0's multi_logloss: 0.160921\n",
            "[74]\tvalid_0's multi_logloss: 0.160728\tvalid_0's multi_logloss: 0.160728\n",
            "[75]\tvalid_0's multi_logloss: 0.160522\tvalid_0's multi_logloss: 0.160522\n",
            "[76]\tvalid_0's multi_logloss: 0.160286\tvalid_0's multi_logloss: 0.160286\n",
            "[77]\tvalid_0's multi_logloss: 0.160158\tvalid_0's multi_logloss: 0.160158\n",
            "[78]\tvalid_0's multi_logloss: 0.160057\tvalid_0's multi_logloss: 0.160057\n",
            "[79]\tvalid_0's multi_logloss: 0.159925\tvalid_0's multi_logloss: 0.159925\n",
            "[80]\tvalid_0's multi_logloss: 0.159735\tvalid_0's multi_logloss: 0.159735\n",
            "[81]\tvalid_0's multi_logloss: 0.159658\tvalid_0's multi_logloss: 0.159658\n",
            "[82]\tvalid_0's multi_logloss: 0.159531\tvalid_0's multi_logloss: 0.159531\n",
            "[83]\tvalid_0's multi_logloss: 0.15941\tvalid_0's multi_logloss: 0.15941\n",
            "[84]\tvalid_0's multi_logloss: 0.15938\tvalid_0's multi_logloss: 0.15938\n",
            "[85]\tvalid_0's multi_logloss: 0.159309\tvalid_0's multi_logloss: 0.159309\n",
            "[86]\tvalid_0's multi_logloss: 0.159227\tvalid_0's multi_logloss: 0.159227\n",
            "[87]\tvalid_0's multi_logloss: 0.159067\tvalid_0's multi_logloss: 0.159067\n",
            "[88]\tvalid_0's multi_logloss: 0.158999\tvalid_0's multi_logloss: 0.158999\n",
            "[89]\tvalid_0's multi_logloss: 0.1589\tvalid_0's multi_logloss: 0.1589\n",
            "[90]\tvalid_0's multi_logloss: 0.158823\tvalid_0's multi_logloss: 0.158823\n",
            "[91]\tvalid_0's multi_logloss: 0.158729\tvalid_0's multi_logloss: 0.158729\n",
            "[92]\tvalid_0's multi_logloss: 0.158697\tvalid_0's multi_logloss: 0.158697\n",
            "[93]\tvalid_0's multi_logloss: 0.158636\tvalid_0's multi_logloss: 0.158636\n",
            "[94]\tvalid_0's multi_logloss: 0.158567\tvalid_0's multi_logloss: 0.158567\n",
            "[95]\tvalid_0's multi_logloss: 0.158529\tvalid_0's multi_logloss: 0.158529\n",
            "[96]\tvalid_0's multi_logloss: 0.158478\tvalid_0's multi_logloss: 0.158478\n",
            "[97]\tvalid_0's multi_logloss: 0.158412\tvalid_0's multi_logloss: 0.158412\n",
            "[98]\tvalid_0's multi_logloss: 0.158379\tvalid_0's multi_logloss: 0.158379\n",
            "[99]\tvalid_0's multi_logloss: 0.15835\tvalid_0's multi_logloss: 0.15835\n",
            "[100]\tvalid_0's multi_logloss: 0.158312\tvalid_0's multi_logloss: 0.158312\n",
            "[101]\tvalid_0's multi_logloss: 0.158303\tvalid_0's multi_logloss: 0.158303\n",
            "[102]\tvalid_0's multi_logloss: 0.158273\tvalid_0's multi_logloss: 0.158273\n",
            "[103]\tvalid_0's multi_logloss: 0.158278\tvalid_0's multi_logloss: 0.158278\n",
            "[104]\tvalid_0's multi_logloss: 0.158249\tvalid_0's multi_logloss: 0.158249\n",
            "[105]\tvalid_0's multi_logloss: 0.158204\tvalid_0's multi_logloss: 0.158204\n",
            "[106]\tvalid_0's multi_logloss: 0.158161\tvalid_0's multi_logloss: 0.158161\n",
            "[107]\tvalid_0's multi_logloss: 0.158144\tvalid_0's multi_logloss: 0.158144\n",
            "[108]\tvalid_0's multi_logloss: 0.158065\tvalid_0's multi_logloss: 0.158065\n",
            "[109]\tvalid_0's multi_logloss: 0.158057\tvalid_0's multi_logloss: 0.158057\n",
            "[110]\tvalid_0's multi_logloss: 0.158044\tvalid_0's multi_logloss: 0.158044\n",
            "[111]\tvalid_0's multi_logloss: 0.158055\tvalid_0's multi_logloss: 0.158055\n",
            "[112]\tvalid_0's multi_logloss: 0.158083\tvalid_0's multi_logloss: 0.158083\n",
            "[113]\tvalid_0's multi_logloss: 0.158086\tvalid_0's multi_logloss: 0.158086\n",
            "[114]\tvalid_0's multi_logloss: 0.158072\tvalid_0's multi_logloss: 0.158072\n",
            "[115]\tvalid_0's multi_logloss: 0.1581\tvalid_0's multi_logloss: 0.1581\n",
            "[116]\tvalid_0's multi_logloss: 0.158059\tvalid_0's multi_logloss: 0.158059\n",
            "[117]\tvalid_0's multi_logloss: 0.158049\tvalid_0's multi_logloss: 0.158049\n",
            "[118]\tvalid_0's multi_logloss: 0.15807\tvalid_0's multi_logloss: 0.15807\n",
            "[119]\tvalid_0's multi_logloss: 0.158009\tvalid_0's multi_logloss: 0.158009\n",
            "[120]\tvalid_0's multi_logloss: 0.158017\tvalid_0's multi_logloss: 0.158017\n",
            "[121]\tvalid_0's multi_logloss: 0.157998\tvalid_0's multi_logloss: 0.157998\n",
            "[122]\tvalid_0's multi_logloss: 0.157999\tvalid_0's multi_logloss: 0.157999\n",
            "[123]\tvalid_0's multi_logloss: 0.158003\tvalid_0's multi_logloss: 0.158003\n",
            "[124]\tvalid_0's multi_logloss: 0.157986\tvalid_0's multi_logloss: 0.157986\n",
            "[125]\tvalid_0's multi_logloss: 0.158016\tvalid_0's multi_logloss: 0.158016\n",
            "[126]\tvalid_0's multi_logloss: 0.158025\tvalid_0's multi_logloss: 0.158025\n",
            "[127]\tvalid_0's multi_logloss: 0.158055\tvalid_0's multi_logloss: 0.158055\n",
            "[128]\tvalid_0's multi_logloss: 0.158101\tvalid_0's multi_logloss: 0.158101\n",
            "[129]\tvalid_0's multi_logloss: 0.158089\tvalid_0's multi_logloss: 0.158089\n",
            "[130]\tvalid_0's multi_logloss: 0.15809\tvalid_0's multi_logloss: 0.15809\n",
            "[131]\tvalid_0's multi_logloss: 0.158106\tvalid_0's multi_logloss: 0.158106\n",
            "[132]\tvalid_0's multi_logloss: 0.158102\tvalid_0's multi_logloss: 0.158102\n",
            "[133]\tvalid_0's multi_logloss: 0.158101\tvalid_0's multi_logloss: 0.158101\n",
            "[134]\tvalid_0's multi_logloss: 0.158087\tvalid_0's multi_logloss: 0.158087\n",
            "Early stopping, best iteration is:\n",
            "[124]\tvalid_0's multi_logloss: 0.157986\tvalid_0's multi_logloss: 0.157986\n",
            "training model for CV #3\n",
            "[1]\tvalid_0's multi_logloss: 0.880301\tvalid_0's multi_logloss: 0.880301\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's multi_logloss: 0.794777\tvalid_0's multi_logloss: 0.794777\n",
            "[3]\tvalid_0's multi_logloss: 0.721537\tvalid_0's multi_logloss: 0.721537\n",
            "[4]\tvalid_0's multi_logloss: 0.662336\tvalid_0's multi_logloss: 0.662336\n",
            "[5]\tvalid_0's multi_logloss: 0.608686\tvalid_0's multi_logloss: 0.608686\n",
            "[6]\tvalid_0's multi_logloss: 0.565477\tvalid_0's multi_logloss: 0.565477\n",
            "[7]\tvalid_0's multi_logloss: 0.525115\tvalid_0's multi_logloss: 0.525115\n",
            "[8]\tvalid_0's multi_logloss: 0.491477\tvalid_0's multi_logloss: 0.491477\n",
            "[9]\tvalid_0's multi_logloss: 0.458324\tvalid_0's multi_logloss: 0.458324\n",
            "[10]\tvalid_0's multi_logloss: 0.432322\tvalid_0's multi_logloss: 0.432322\n",
            "[11]\tvalid_0's multi_logloss: 0.408094\tvalid_0's multi_logloss: 0.408094\n",
            "[12]\tvalid_0's multi_logloss: 0.383703\tvalid_0's multi_logloss: 0.383703\n",
            "[13]\tvalid_0's multi_logloss: 0.365283\tvalid_0's multi_logloss: 0.365283\n",
            "[14]\tvalid_0's multi_logloss: 0.346485\tvalid_0's multi_logloss: 0.346485\n",
            "[15]\tvalid_0's multi_logloss: 0.331856\tvalid_0's multi_logloss: 0.331856\n",
            "[16]\tvalid_0's multi_logloss: 0.316722\tvalid_0's multi_logloss: 0.316722\n",
            "[17]\tvalid_0's multi_logloss: 0.302326\tvalid_0's multi_logloss: 0.302326\n",
            "[18]\tvalid_0's multi_logloss: 0.291075\tvalid_0's multi_logloss: 0.291075\n",
            "[19]\tvalid_0's multi_logloss: 0.280067\tvalid_0's multi_logloss: 0.280067\n",
            "[20]\tvalid_0's multi_logloss: 0.270795\tvalid_0's multi_logloss: 0.270795\n",
            "[21]\tvalid_0's multi_logloss: 0.261617\tvalid_0's multi_logloss: 0.261617\n",
            "[22]\tvalid_0's multi_logloss: 0.253875\tvalid_0's multi_logloss: 0.253875\n",
            "[23]\tvalid_0's multi_logloss: 0.245563\tvalid_0's multi_logloss: 0.245563\n",
            "[24]\tvalid_0's multi_logloss: 0.238565\tvalid_0's multi_logloss: 0.238565\n",
            "[25]\tvalid_0's multi_logloss: 0.232424\tvalid_0's multi_logloss: 0.232424\n",
            "[26]\tvalid_0's multi_logloss: 0.226251\tvalid_0's multi_logloss: 0.226251\n",
            "[27]\tvalid_0's multi_logloss: 0.221051\tvalid_0's multi_logloss: 0.221051\n",
            "[28]\tvalid_0's multi_logloss: 0.216616\tvalid_0's multi_logloss: 0.216616\n",
            "[29]\tvalid_0's multi_logloss: 0.211828\tvalid_0's multi_logloss: 0.211828\n",
            "[30]\tvalid_0's multi_logloss: 0.208376\tvalid_0's multi_logloss: 0.208376\n",
            "[31]\tvalid_0's multi_logloss: 0.204998\tvalid_0's multi_logloss: 0.204998\n",
            "[32]\tvalid_0's multi_logloss: 0.201239\tvalid_0's multi_logloss: 0.201239\n",
            "[33]\tvalid_0's multi_logloss: 0.198327\tvalid_0's multi_logloss: 0.198327\n",
            "[34]\tvalid_0's multi_logloss: 0.195071\tvalid_0's multi_logloss: 0.195071\n",
            "[35]\tvalid_0's multi_logloss: 0.192421\tvalid_0's multi_logloss: 0.192421\n",
            "[36]\tvalid_0's multi_logloss: 0.190264\tvalid_0's multi_logloss: 0.190264\n",
            "[37]\tvalid_0's multi_logloss: 0.187719\tvalid_0's multi_logloss: 0.187719\n",
            "[38]\tvalid_0's multi_logloss: 0.185745\tvalid_0's multi_logloss: 0.185745\n",
            "[39]\tvalid_0's multi_logloss: 0.183755\tvalid_0's multi_logloss: 0.183755\n",
            "[40]\tvalid_0's multi_logloss: 0.181767\tvalid_0's multi_logloss: 0.181767\n",
            "[41]\tvalid_0's multi_logloss: 0.180045\tvalid_0's multi_logloss: 0.180045\n",
            "[42]\tvalid_0's multi_logloss: 0.178738\tvalid_0's multi_logloss: 0.178738\n",
            "[43]\tvalid_0's multi_logloss: 0.177326\tvalid_0's multi_logloss: 0.177326\n",
            "[44]\tvalid_0's multi_logloss: 0.176161\tvalid_0's multi_logloss: 0.176161\n",
            "[45]\tvalid_0's multi_logloss: 0.174951\tvalid_0's multi_logloss: 0.174951\n",
            "[46]\tvalid_0's multi_logloss: 0.173936\tvalid_0's multi_logloss: 0.173936\n",
            "[47]\tvalid_0's multi_logloss: 0.17297\tvalid_0's multi_logloss: 0.17297\n",
            "[48]\tvalid_0's multi_logloss: 0.172262\tvalid_0's multi_logloss: 0.172262\n",
            "[49]\tvalid_0's multi_logloss: 0.171502\tvalid_0's multi_logloss: 0.171502\n",
            "[50]\tvalid_0's multi_logloss: 0.17065\tvalid_0's multi_logloss: 0.17065\n",
            "[51]\tvalid_0's multi_logloss: 0.170066\tvalid_0's multi_logloss: 0.170066\n",
            "[52]\tvalid_0's multi_logloss: 0.169337\tvalid_0's multi_logloss: 0.169337\n",
            "[53]\tvalid_0's multi_logloss: 0.168645\tvalid_0's multi_logloss: 0.168645\n",
            "[54]\tvalid_0's multi_logloss: 0.16814\tvalid_0's multi_logloss: 0.16814\n",
            "[55]\tvalid_0's multi_logloss: 0.167716\tvalid_0's multi_logloss: 0.167716\n",
            "[56]\tvalid_0's multi_logloss: 0.167188\tvalid_0's multi_logloss: 0.167188\n",
            "[57]\tvalid_0's multi_logloss: 0.166897\tvalid_0's multi_logloss: 0.166897\n",
            "[58]\tvalid_0's multi_logloss: 0.166327\tvalid_0's multi_logloss: 0.166327\n",
            "[59]\tvalid_0's multi_logloss: 0.165812\tvalid_0's multi_logloss: 0.165812\n",
            "[60]\tvalid_0's multi_logloss: 0.165452\tvalid_0's multi_logloss: 0.165452\n",
            "[61]\tvalid_0's multi_logloss: 0.165207\tvalid_0's multi_logloss: 0.165207\n",
            "[62]\tvalid_0's multi_logloss: 0.164841\tvalid_0's multi_logloss: 0.164841\n",
            "[63]\tvalid_0's multi_logloss: 0.164411\tvalid_0's multi_logloss: 0.164411\n",
            "[64]\tvalid_0's multi_logloss: 0.164063\tvalid_0's multi_logloss: 0.164063\n",
            "[65]\tvalid_0's multi_logloss: 0.163814\tvalid_0's multi_logloss: 0.163814\n",
            "[66]\tvalid_0's multi_logloss: 0.163576\tvalid_0's multi_logloss: 0.163576\n",
            "[67]\tvalid_0's multi_logloss: 0.163267\tvalid_0's multi_logloss: 0.163267\n",
            "[68]\tvalid_0's multi_logloss: 0.163021\tvalid_0's multi_logloss: 0.163021\n",
            "[69]\tvalid_0's multi_logloss: 0.162806\tvalid_0's multi_logloss: 0.162806\n",
            "[70]\tvalid_0's multi_logloss: 0.162537\tvalid_0's multi_logloss: 0.162537\n",
            "[71]\tvalid_0's multi_logloss: 0.162376\tvalid_0's multi_logloss: 0.162376\n",
            "[72]\tvalid_0's multi_logloss: 0.162091\tvalid_0's multi_logloss: 0.162091\n",
            "[73]\tvalid_0's multi_logloss: 0.161979\tvalid_0's multi_logloss: 0.161979\n",
            "[74]\tvalid_0's multi_logloss: 0.161736\tvalid_0's multi_logloss: 0.161736\n",
            "[75]\tvalid_0's multi_logloss: 0.161563\tvalid_0's multi_logloss: 0.161563\n",
            "[76]\tvalid_0's multi_logloss: 0.161417\tvalid_0's multi_logloss: 0.161417\n",
            "[77]\tvalid_0's multi_logloss: 0.161223\tvalid_0's multi_logloss: 0.161223\n",
            "[78]\tvalid_0's multi_logloss: 0.161037\tvalid_0's multi_logloss: 0.161037\n",
            "[79]\tvalid_0's multi_logloss: 0.16093\tvalid_0's multi_logloss: 0.16093\n",
            "[80]\tvalid_0's multi_logloss: 0.160766\tvalid_0's multi_logloss: 0.160766\n",
            "[81]\tvalid_0's multi_logloss: 0.160657\tvalid_0's multi_logloss: 0.160657\n",
            "[82]\tvalid_0's multi_logloss: 0.160587\tvalid_0's multi_logloss: 0.160587\n",
            "[83]\tvalid_0's multi_logloss: 0.160435\tvalid_0's multi_logloss: 0.160435\n",
            "[84]\tvalid_0's multi_logloss: 0.160409\tvalid_0's multi_logloss: 0.160409\n",
            "[85]\tvalid_0's multi_logloss: 0.160304\tvalid_0's multi_logloss: 0.160304\n",
            "[86]\tvalid_0's multi_logloss: 0.160215\tvalid_0's multi_logloss: 0.160215\n",
            "[87]\tvalid_0's multi_logloss: 0.160046\tvalid_0's multi_logloss: 0.160046\n",
            "[88]\tvalid_0's multi_logloss: 0.15988\tvalid_0's multi_logloss: 0.15988\n",
            "[89]\tvalid_0's multi_logloss: 0.159744\tvalid_0's multi_logloss: 0.159744\n",
            "[90]\tvalid_0's multi_logloss: 0.159735\tvalid_0's multi_logloss: 0.159735\n",
            "[91]\tvalid_0's multi_logloss: 0.159619\tvalid_0's multi_logloss: 0.159619\n",
            "[92]\tvalid_0's multi_logloss: 0.159558\tvalid_0's multi_logloss: 0.159558\n",
            "[93]\tvalid_0's multi_logloss: 0.15951\tvalid_0's multi_logloss: 0.15951\n",
            "[94]\tvalid_0's multi_logloss: 0.159446\tvalid_0's multi_logloss: 0.159446\n",
            "[95]\tvalid_0's multi_logloss: 0.159396\tvalid_0's multi_logloss: 0.159396\n",
            "[96]\tvalid_0's multi_logloss: 0.159377\tvalid_0's multi_logloss: 0.159377\n",
            "[97]\tvalid_0's multi_logloss: 0.159296\tvalid_0's multi_logloss: 0.159296\n",
            "[98]\tvalid_0's multi_logloss: 0.159301\tvalid_0's multi_logloss: 0.159301\n",
            "[99]\tvalid_0's multi_logloss: 0.159205\tvalid_0's multi_logloss: 0.159205\n",
            "[100]\tvalid_0's multi_logloss: 0.15916\tvalid_0's multi_logloss: 0.15916\n",
            "[101]\tvalid_0's multi_logloss: 0.159135\tvalid_0's multi_logloss: 0.159135\n",
            "[102]\tvalid_0's multi_logloss: 0.159051\tvalid_0's multi_logloss: 0.159051\n",
            "[103]\tvalid_0's multi_logloss: 0.159048\tvalid_0's multi_logloss: 0.159048\n",
            "[104]\tvalid_0's multi_logloss: 0.158996\tvalid_0's multi_logloss: 0.158996\n",
            "[105]\tvalid_0's multi_logloss: 0.158973\tvalid_0's multi_logloss: 0.158973\n",
            "[106]\tvalid_0's multi_logloss: 0.158922\tvalid_0's multi_logloss: 0.158922\n",
            "[107]\tvalid_0's multi_logloss: 0.158913\tvalid_0's multi_logloss: 0.158913\n",
            "[108]\tvalid_0's multi_logloss: 0.158864\tvalid_0's multi_logloss: 0.158864\n",
            "[109]\tvalid_0's multi_logloss: 0.15882\tvalid_0's multi_logloss: 0.15882\n",
            "[110]\tvalid_0's multi_logloss: 0.158818\tvalid_0's multi_logloss: 0.158818\n",
            "[111]\tvalid_0's multi_logloss: 0.158794\tvalid_0's multi_logloss: 0.158794\n",
            "[112]\tvalid_0's multi_logloss: 0.158852\tvalid_0's multi_logloss: 0.158852\n",
            "[113]\tvalid_0's multi_logloss: 0.158809\tvalid_0's multi_logloss: 0.158809\n",
            "[114]\tvalid_0's multi_logloss: 0.158792\tvalid_0's multi_logloss: 0.158792\n",
            "[115]\tvalid_0's multi_logloss: 0.158759\tvalid_0's multi_logloss: 0.158759\n",
            "[116]\tvalid_0's multi_logloss: 0.158794\tvalid_0's multi_logloss: 0.158794\n",
            "[117]\tvalid_0's multi_logloss: 0.158771\tvalid_0's multi_logloss: 0.158771\n",
            "[118]\tvalid_0's multi_logloss: 0.158762\tvalid_0's multi_logloss: 0.158762\n",
            "[119]\tvalid_0's multi_logloss: 0.158745\tvalid_0's multi_logloss: 0.158745\n",
            "[120]\tvalid_0's multi_logloss: 0.158732\tvalid_0's multi_logloss: 0.158732\n",
            "[121]\tvalid_0's multi_logloss: 0.158744\tvalid_0's multi_logloss: 0.158744\n",
            "[122]\tvalid_0's multi_logloss: 0.158773\tvalid_0's multi_logloss: 0.158773\n",
            "[123]\tvalid_0's multi_logloss: 0.158789\tvalid_0's multi_logloss: 0.158789\n",
            "[124]\tvalid_0's multi_logloss: 0.158795\tvalid_0's multi_logloss: 0.158795\n",
            "[125]\tvalid_0's multi_logloss: 0.158818\tvalid_0's multi_logloss: 0.158818\n",
            "[126]\tvalid_0's multi_logloss: 0.158828\tvalid_0's multi_logloss: 0.158828\n",
            "[127]\tvalid_0's multi_logloss: 0.158823\tvalid_0's multi_logloss: 0.158823\n",
            "[128]\tvalid_0's multi_logloss: 0.158788\tvalid_0's multi_logloss: 0.158788\n",
            "[129]\tvalid_0's multi_logloss: 0.158814\tvalid_0's multi_logloss: 0.158814\n",
            "[130]\tvalid_0's multi_logloss: 0.158814\tvalid_0's multi_logloss: 0.158814\n",
            "Early stopping, best iteration is:\n",
            "[120]\tvalid_0's multi_logloss: 0.158732\tvalid_0's multi_logloss: 0.158732\n",
            "training model for CV #4\n",
            "[1]\tvalid_0's multi_logloss: 0.880201\tvalid_0's multi_logloss: 0.880201\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's multi_logloss: 0.79469\tvalid_0's multi_logloss: 0.79469\n",
            "[3]\tvalid_0's multi_logloss: 0.721721\tvalid_0's multi_logloss: 0.721721\n",
            "[4]\tvalid_0's multi_logloss: 0.662685\tvalid_0's multi_logloss: 0.662685\n",
            "[5]\tvalid_0's multi_logloss: 0.608874\tvalid_0's multi_logloss: 0.608874\n",
            "[6]\tvalid_0's multi_logloss: 0.565308\tvalid_0's multi_logloss: 0.565308\n",
            "[7]\tvalid_0's multi_logloss: 0.524797\tvalid_0's multi_logloss: 0.524797\n",
            "[8]\tvalid_0's multi_logloss: 0.491152\tvalid_0's multi_logloss: 0.491152\n",
            "[9]\tvalid_0's multi_logloss: 0.45801\tvalid_0's multi_logloss: 0.45801\n",
            "[10]\tvalid_0's multi_logloss: 0.432057\tvalid_0's multi_logloss: 0.432057\n",
            "[11]\tvalid_0's multi_logloss: 0.407615\tvalid_0's multi_logloss: 0.407615\n",
            "[12]\tvalid_0's multi_logloss: 0.383234\tvalid_0's multi_logloss: 0.383234\n",
            "[13]\tvalid_0's multi_logloss: 0.36471\tvalid_0's multi_logloss: 0.36471\n",
            "[14]\tvalid_0's multi_logloss: 0.345985\tvalid_0's multi_logloss: 0.345985\n",
            "[15]\tvalid_0's multi_logloss: 0.331361\tvalid_0's multi_logloss: 0.331361\n",
            "[16]\tvalid_0's multi_logloss: 0.316167\tvalid_0's multi_logloss: 0.316167\n",
            "[17]\tvalid_0's multi_logloss: 0.301728\tvalid_0's multi_logloss: 0.301728\n",
            "[18]\tvalid_0's multi_logloss: 0.290437\tvalid_0's multi_logloss: 0.290437\n",
            "[19]\tvalid_0's multi_logloss: 0.279506\tvalid_0's multi_logloss: 0.279506\n",
            "[20]\tvalid_0's multi_logloss: 0.270243\tvalid_0's multi_logloss: 0.270243\n",
            "[21]\tvalid_0's multi_logloss: 0.261057\tvalid_0's multi_logloss: 0.261057\n",
            "[22]\tvalid_0's multi_logloss: 0.253167\tvalid_0's multi_logloss: 0.253167\n",
            "[23]\tvalid_0's multi_logloss: 0.244791\tvalid_0's multi_logloss: 0.244791\n",
            "[24]\tvalid_0's multi_logloss: 0.237824\tvalid_0's multi_logloss: 0.237824\n",
            "[25]\tvalid_0's multi_logloss: 0.231598\tvalid_0's multi_logloss: 0.231598\n",
            "[26]\tvalid_0's multi_logloss: 0.225322\tvalid_0's multi_logloss: 0.225322\n",
            "[27]\tvalid_0's multi_logloss: 0.22006\tvalid_0's multi_logloss: 0.22006\n",
            "[28]\tvalid_0's multi_logloss: 0.215639\tvalid_0's multi_logloss: 0.215639\n",
            "[29]\tvalid_0's multi_logloss: 0.210867\tvalid_0's multi_logloss: 0.210867\n",
            "[30]\tvalid_0's multi_logloss: 0.207348\tvalid_0's multi_logloss: 0.207348\n",
            "[31]\tvalid_0's multi_logloss: 0.203981\tvalid_0's multi_logloss: 0.203981\n",
            "[32]\tvalid_0's multi_logloss: 0.200176\tvalid_0's multi_logloss: 0.200176\n",
            "[33]\tvalid_0's multi_logloss: 0.197181\tvalid_0's multi_logloss: 0.197181\n",
            "[34]\tvalid_0's multi_logloss: 0.193943\tvalid_0's multi_logloss: 0.193943\n",
            "[35]\tvalid_0's multi_logloss: 0.191222\tvalid_0's multi_logloss: 0.191222\n",
            "[36]\tvalid_0's multi_logloss: 0.189126\tvalid_0's multi_logloss: 0.189126\n",
            "[37]\tvalid_0's multi_logloss: 0.186671\tvalid_0's multi_logloss: 0.186671\n",
            "[38]\tvalid_0's multi_logloss: 0.184689\tvalid_0's multi_logloss: 0.184689\n",
            "[39]\tvalid_0's multi_logloss: 0.182717\tvalid_0's multi_logloss: 0.182717\n",
            "[40]\tvalid_0's multi_logloss: 0.180768\tvalid_0's multi_logloss: 0.180768\n",
            "[41]\tvalid_0's multi_logloss: 0.17905\tvalid_0's multi_logloss: 0.17905\n",
            "[42]\tvalid_0's multi_logloss: 0.177835\tvalid_0's multi_logloss: 0.177835\n",
            "[43]\tvalid_0's multi_logloss: 0.176439\tvalid_0's multi_logloss: 0.176439\n",
            "[44]\tvalid_0's multi_logloss: 0.175212\tvalid_0's multi_logloss: 0.175212\n",
            "[45]\tvalid_0's multi_logloss: 0.17398\tvalid_0's multi_logloss: 0.17398\n",
            "[46]\tvalid_0's multi_logloss: 0.173026\tvalid_0's multi_logloss: 0.173026\n",
            "[47]\tvalid_0's multi_logloss: 0.172026\tvalid_0's multi_logloss: 0.172026\n",
            "[48]\tvalid_0's multi_logloss: 0.171301\tvalid_0's multi_logloss: 0.171301\n",
            "[49]\tvalid_0's multi_logloss: 0.170474\tvalid_0's multi_logloss: 0.170474\n",
            "[50]\tvalid_0's multi_logloss: 0.169663\tvalid_0's multi_logloss: 0.169663\n",
            "[51]\tvalid_0's multi_logloss: 0.169045\tvalid_0's multi_logloss: 0.169045\n",
            "[52]\tvalid_0's multi_logloss: 0.168297\tvalid_0's multi_logloss: 0.168297\n",
            "[53]\tvalid_0's multi_logloss: 0.16761\tvalid_0's multi_logloss: 0.16761\n",
            "[54]\tvalid_0's multi_logloss: 0.167048\tvalid_0's multi_logloss: 0.167048\n",
            "[55]\tvalid_0's multi_logloss: 0.166582\tvalid_0's multi_logloss: 0.166582\n",
            "[56]\tvalid_0's multi_logloss: 0.166011\tvalid_0's multi_logloss: 0.166011\n",
            "[57]\tvalid_0's multi_logloss: 0.165691\tvalid_0's multi_logloss: 0.165691\n",
            "[58]\tvalid_0's multi_logloss: 0.165058\tvalid_0's multi_logloss: 0.165058\n",
            "[59]\tvalid_0's multi_logloss: 0.16456\tvalid_0's multi_logloss: 0.16456\n",
            "[60]\tvalid_0's multi_logloss: 0.164325\tvalid_0's multi_logloss: 0.164325\n",
            "[61]\tvalid_0's multi_logloss: 0.164055\tvalid_0's multi_logloss: 0.164055\n",
            "[62]\tvalid_0's multi_logloss: 0.163671\tvalid_0's multi_logloss: 0.163671\n",
            "[63]\tvalid_0's multi_logloss: 0.163275\tvalid_0's multi_logloss: 0.163275\n",
            "[64]\tvalid_0's multi_logloss: 0.162914\tvalid_0's multi_logloss: 0.162914\n",
            "[65]\tvalid_0's multi_logloss: 0.162561\tvalid_0's multi_logloss: 0.162561\n",
            "[66]\tvalid_0's multi_logloss: 0.162335\tvalid_0's multi_logloss: 0.162335\n",
            "[67]\tvalid_0's multi_logloss: 0.162024\tvalid_0's multi_logloss: 0.162024\n",
            "[68]\tvalid_0's multi_logloss: 0.161784\tvalid_0's multi_logloss: 0.161784\n",
            "[69]\tvalid_0's multi_logloss: 0.161557\tvalid_0's multi_logloss: 0.161557\n",
            "[70]\tvalid_0's multi_logloss: 0.161272\tvalid_0's multi_logloss: 0.161272\n",
            "[71]\tvalid_0's multi_logloss: 0.161107\tvalid_0's multi_logloss: 0.161107\n",
            "[72]\tvalid_0's multi_logloss: 0.16084\tvalid_0's multi_logloss: 0.16084\n",
            "[73]\tvalid_0's multi_logloss: 0.16065\tvalid_0's multi_logloss: 0.16065\n",
            "[74]\tvalid_0's multi_logloss: 0.160477\tvalid_0's multi_logloss: 0.160477\n",
            "[75]\tvalid_0's multi_logloss: 0.160298\tvalid_0's multi_logloss: 0.160298\n",
            "[76]\tvalid_0's multi_logloss: 0.160113\tvalid_0's multi_logloss: 0.160113\n",
            "[77]\tvalid_0's multi_logloss: 0.159955\tvalid_0's multi_logloss: 0.159955\n",
            "[78]\tvalid_0's multi_logloss: 0.159793\tvalid_0's multi_logloss: 0.159793\n",
            "[79]\tvalid_0's multi_logloss: 0.159687\tvalid_0's multi_logloss: 0.159687\n",
            "[80]\tvalid_0's multi_logloss: 0.159543\tvalid_0's multi_logloss: 0.159543\n",
            "[81]\tvalid_0's multi_logloss: 0.159425\tvalid_0's multi_logloss: 0.159425\n",
            "[82]\tvalid_0's multi_logloss: 0.159303\tvalid_0's multi_logloss: 0.159303\n",
            "[83]\tvalid_0's multi_logloss: 0.159145\tvalid_0's multi_logloss: 0.159145\n",
            "[84]\tvalid_0's multi_logloss: 0.159085\tvalid_0's multi_logloss: 0.159085\n",
            "[85]\tvalid_0's multi_logloss: 0.15899\tvalid_0's multi_logloss: 0.15899\n",
            "[86]\tvalid_0's multi_logloss: 0.158866\tvalid_0's multi_logloss: 0.158866\n",
            "[87]\tvalid_0's multi_logloss: 0.158775\tvalid_0's multi_logloss: 0.158775\n",
            "[88]\tvalid_0's multi_logloss: 0.158712\tvalid_0's multi_logloss: 0.158712\n",
            "[89]\tvalid_0's multi_logloss: 0.158544\tvalid_0's multi_logloss: 0.158544\n",
            "[90]\tvalid_0's multi_logloss: 0.158488\tvalid_0's multi_logloss: 0.158488\n",
            "[91]\tvalid_0's multi_logloss: 0.158413\tvalid_0's multi_logloss: 0.158413\n",
            "[92]\tvalid_0's multi_logloss: 0.158333\tvalid_0's multi_logloss: 0.158333\n",
            "[93]\tvalid_0's multi_logloss: 0.158318\tvalid_0's multi_logloss: 0.158318\n",
            "[94]\tvalid_0's multi_logloss: 0.158271\tvalid_0's multi_logloss: 0.158271\n",
            "[95]\tvalid_0's multi_logloss: 0.158224\tvalid_0's multi_logloss: 0.158224\n",
            "[96]\tvalid_0's multi_logloss: 0.15821\tvalid_0's multi_logloss: 0.15821\n",
            "[97]\tvalid_0's multi_logloss: 0.158193\tvalid_0's multi_logloss: 0.158193\n",
            "[98]\tvalid_0's multi_logloss: 0.158186\tvalid_0's multi_logloss: 0.158186\n",
            "[99]\tvalid_0's multi_logloss: 0.158134\tvalid_0's multi_logloss: 0.158134\n",
            "[100]\tvalid_0's multi_logloss: 0.158125\tvalid_0's multi_logloss: 0.158125\n",
            "[101]\tvalid_0's multi_logloss: 0.158149\tvalid_0's multi_logloss: 0.158149\n",
            "[102]\tvalid_0's multi_logloss: 0.158123\tvalid_0's multi_logloss: 0.158123\n",
            "[103]\tvalid_0's multi_logloss: 0.158062\tvalid_0's multi_logloss: 0.158062\n",
            "[104]\tvalid_0's multi_logloss: 0.158023\tvalid_0's multi_logloss: 0.158023\n",
            "[105]\tvalid_0's multi_logloss: 0.157984\tvalid_0's multi_logloss: 0.157984\n",
            "[106]\tvalid_0's multi_logloss: 0.157994\tvalid_0's multi_logloss: 0.157994\n",
            "[107]\tvalid_0's multi_logloss: 0.157987\tvalid_0's multi_logloss: 0.157987\n",
            "[108]\tvalid_0's multi_logloss: 0.157922\tvalid_0's multi_logloss: 0.157922\n",
            "[109]\tvalid_0's multi_logloss: 0.157896\tvalid_0's multi_logloss: 0.157896\n",
            "[110]\tvalid_0's multi_logloss: 0.157888\tvalid_0's multi_logloss: 0.157888\n",
            "[111]\tvalid_0's multi_logloss: 0.157847\tvalid_0's multi_logloss: 0.157847\n",
            "[112]\tvalid_0's multi_logloss: 0.157845\tvalid_0's multi_logloss: 0.157845\n",
            "[113]\tvalid_0's multi_logloss: 0.157827\tvalid_0's multi_logloss: 0.157827\n",
            "[114]\tvalid_0's multi_logloss: 0.157827\tvalid_0's multi_logloss: 0.157827\n",
            "[115]\tvalid_0's multi_logloss: 0.157805\tvalid_0's multi_logloss: 0.157805\n",
            "[116]\tvalid_0's multi_logloss: 0.157789\tvalid_0's multi_logloss: 0.157789\n",
            "[117]\tvalid_0's multi_logloss: 0.157801\tvalid_0's multi_logloss: 0.157801\n",
            "[118]\tvalid_0's multi_logloss: 0.157807\tvalid_0's multi_logloss: 0.157807\n",
            "[119]\tvalid_0's multi_logloss: 0.157827\tvalid_0's multi_logloss: 0.157827\n",
            "[120]\tvalid_0's multi_logloss: 0.157869\tvalid_0's multi_logloss: 0.157869\n",
            "[121]\tvalid_0's multi_logloss: 0.157879\tvalid_0's multi_logloss: 0.157879\n",
            "[122]\tvalid_0's multi_logloss: 0.157845\tvalid_0's multi_logloss: 0.157845\n",
            "[123]\tvalid_0's multi_logloss: 0.15783\tvalid_0's multi_logloss: 0.15783\n",
            "[124]\tvalid_0's multi_logloss: 0.157833\tvalid_0's multi_logloss: 0.157833\n",
            "[125]\tvalid_0's multi_logloss: 0.157874\tvalid_0's multi_logloss: 0.157874\n",
            "[126]\tvalid_0's multi_logloss: 0.157874\tvalid_0's multi_logloss: 0.157874\n",
            "Early stopping, best iteration is:\n",
            "[116]\tvalid_0's multi_logloss: 0.157789\tvalid_0's multi_logloss: 0.157789\n",
            "training model for CV #5\n",
            "[1]\tvalid_0's multi_logloss: 0.880122\tvalid_0's multi_logloss: 0.880122\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's multi_logloss: 0.794459\tvalid_0's multi_logloss: 0.794459\n",
            "[3]\tvalid_0's multi_logloss: 0.721103\tvalid_0's multi_logloss: 0.721103\n",
            "[4]\tvalid_0's multi_logloss: 0.661992\tvalid_0's multi_logloss: 0.661992\n",
            "[5]\tvalid_0's multi_logloss: 0.608126\tvalid_0's multi_logloss: 0.608126\n",
            "[6]\tvalid_0's multi_logloss: 0.564724\tvalid_0's multi_logloss: 0.564724\n",
            "[7]\tvalid_0's multi_logloss: 0.524154\tvalid_0's multi_logloss: 0.524154\n",
            "[8]\tvalid_0's multi_logloss: 0.490466\tvalid_0's multi_logloss: 0.490466\n",
            "[9]\tvalid_0's multi_logloss: 0.457297\tvalid_0's multi_logloss: 0.457297\n",
            "[10]\tvalid_0's multi_logloss: 0.431176\tvalid_0's multi_logloss: 0.431176\n",
            "[11]\tvalid_0's multi_logloss: 0.406779\tvalid_0's multi_logloss: 0.406779\n",
            "[12]\tvalid_0's multi_logloss: 0.382413\tvalid_0's multi_logloss: 0.382413\n",
            "[13]\tvalid_0's multi_logloss: 0.363757\tvalid_0's multi_logloss: 0.363757\n",
            "[14]\tvalid_0's multi_logloss: 0.344845\tvalid_0's multi_logloss: 0.344845\n",
            "[15]\tvalid_0's multi_logloss: 0.330264\tvalid_0's multi_logloss: 0.330264\n",
            "[16]\tvalid_0's multi_logloss: 0.314939\tvalid_0's multi_logloss: 0.314939\n",
            "[17]\tvalid_0's multi_logloss: 0.300439\tvalid_0's multi_logloss: 0.300439\n",
            "[18]\tvalid_0's multi_logloss: 0.289115\tvalid_0's multi_logloss: 0.289115\n",
            "[19]\tvalid_0's multi_logloss: 0.278014\tvalid_0's multi_logloss: 0.278014\n",
            "[20]\tvalid_0's multi_logloss: 0.268737\tvalid_0's multi_logloss: 0.268737\n",
            "[21]\tvalid_0's multi_logloss: 0.25952\tvalid_0's multi_logloss: 0.25952\n",
            "[22]\tvalid_0's multi_logloss: 0.251642\tvalid_0's multi_logloss: 0.251642\n",
            "[23]\tvalid_0's multi_logloss: 0.243284\tvalid_0's multi_logloss: 0.243284\n",
            "[24]\tvalid_0's multi_logloss: 0.236239\tvalid_0's multi_logloss: 0.236239\n",
            "[25]\tvalid_0's multi_logloss: 0.230102\tvalid_0's multi_logloss: 0.230102\n",
            "[26]\tvalid_0's multi_logloss: 0.223888\tvalid_0's multi_logloss: 0.223888\n",
            "[27]\tvalid_0's multi_logloss: 0.218651\tvalid_0's multi_logloss: 0.218651\n",
            "[28]\tvalid_0's multi_logloss: 0.214179\tvalid_0's multi_logloss: 0.214179\n",
            "[29]\tvalid_0's multi_logloss: 0.20944\tvalid_0's multi_logloss: 0.20944\n",
            "[30]\tvalid_0's multi_logloss: 0.205944\tvalid_0's multi_logloss: 0.205944\n",
            "[31]\tvalid_0's multi_logloss: 0.202609\tvalid_0's multi_logloss: 0.202609\n",
            "[32]\tvalid_0's multi_logloss: 0.198757\tvalid_0's multi_logloss: 0.198757\n",
            "[33]\tvalid_0's multi_logloss: 0.195796\tvalid_0's multi_logloss: 0.195796\n",
            "[34]\tvalid_0's multi_logloss: 0.19259\tvalid_0's multi_logloss: 0.19259\n",
            "[35]\tvalid_0's multi_logloss: 0.18994\tvalid_0's multi_logloss: 0.18994\n",
            "[36]\tvalid_0's multi_logloss: 0.187622\tvalid_0's multi_logloss: 0.187622\n",
            "[37]\tvalid_0's multi_logloss: 0.185034\tvalid_0's multi_logloss: 0.185034\n",
            "[38]\tvalid_0's multi_logloss: 0.183013\tvalid_0's multi_logloss: 0.183013\n",
            "[39]\tvalid_0's multi_logloss: 0.181006\tvalid_0's multi_logloss: 0.181006\n",
            "[40]\tvalid_0's multi_logloss: 0.179102\tvalid_0's multi_logloss: 0.179102\n",
            "[41]\tvalid_0's multi_logloss: 0.177388\tvalid_0's multi_logloss: 0.177388\n",
            "[42]\tvalid_0's multi_logloss: 0.17614\tvalid_0's multi_logloss: 0.17614\n",
            "[43]\tvalid_0's multi_logloss: 0.174736\tvalid_0's multi_logloss: 0.174736\n",
            "[44]\tvalid_0's multi_logloss: 0.173508\tvalid_0's multi_logloss: 0.173508\n",
            "[45]\tvalid_0's multi_logloss: 0.172203\tvalid_0's multi_logloss: 0.172203\n",
            "[46]\tvalid_0's multi_logloss: 0.1712\tvalid_0's multi_logloss: 0.1712\n",
            "[47]\tvalid_0's multi_logloss: 0.170192\tvalid_0's multi_logloss: 0.170192\n",
            "[48]\tvalid_0's multi_logloss: 0.169457\tvalid_0's multi_logloss: 0.169457\n",
            "[49]\tvalid_0's multi_logloss: 0.168748\tvalid_0's multi_logloss: 0.168748\n",
            "[50]\tvalid_0's multi_logloss: 0.167924\tvalid_0's multi_logloss: 0.167924\n",
            "[51]\tvalid_0's multi_logloss: 0.167208\tvalid_0's multi_logloss: 0.167208\n",
            "[52]\tvalid_0's multi_logloss: 0.166448\tvalid_0's multi_logloss: 0.166448\n",
            "[53]\tvalid_0's multi_logloss: 0.165754\tvalid_0's multi_logloss: 0.165754\n",
            "[54]\tvalid_0's multi_logloss: 0.165246\tvalid_0's multi_logloss: 0.165246\n",
            "[55]\tvalid_0's multi_logloss: 0.164812\tvalid_0's multi_logloss: 0.164812\n",
            "[56]\tvalid_0's multi_logloss: 0.164201\tvalid_0's multi_logloss: 0.164201\n",
            "[57]\tvalid_0's multi_logloss: 0.163833\tvalid_0's multi_logloss: 0.163833\n",
            "[58]\tvalid_0's multi_logloss: 0.163251\tvalid_0's multi_logloss: 0.163251\n",
            "[59]\tvalid_0's multi_logloss: 0.162721\tvalid_0's multi_logloss: 0.162721\n",
            "[60]\tvalid_0's multi_logloss: 0.162463\tvalid_0's multi_logloss: 0.162463\n",
            "[61]\tvalid_0's multi_logloss: 0.162216\tvalid_0's multi_logloss: 0.162216\n",
            "[62]\tvalid_0's multi_logloss: 0.161853\tvalid_0's multi_logloss: 0.161853\n",
            "[63]\tvalid_0's multi_logloss: 0.161355\tvalid_0's multi_logloss: 0.161355\n",
            "[64]\tvalid_0's multi_logloss: 0.161011\tvalid_0's multi_logloss: 0.161011\n",
            "[65]\tvalid_0's multi_logloss: 0.16073\tvalid_0's multi_logloss: 0.16073\n",
            "[66]\tvalid_0's multi_logloss: 0.160533\tvalid_0's multi_logloss: 0.160533\n",
            "[67]\tvalid_0's multi_logloss: 0.16027\tvalid_0's multi_logloss: 0.16027\n",
            "[68]\tvalid_0's multi_logloss: 0.16002\tvalid_0's multi_logloss: 0.16002\n",
            "[69]\tvalid_0's multi_logloss: 0.159818\tvalid_0's multi_logloss: 0.159818\n",
            "[70]\tvalid_0's multi_logloss: 0.159488\tvalid_0's multi_logloss: 0.159488\n",
            "[71]\tvalid_0's multi_logloss: 0.15929\tvalid_0's multi_logloss: 0.15929\n",
            "[72]\tvalid_0's multi_logloss: 0.158978\tvalid_0's multi_logloss: 0.158978\n",
            "[73]\tvalid_0's multi_logloss: 0.158792\tvalid_0's multi_logloss: 0.158792\n",
            "[74]\tvalid_0's multi_logloss: 0.158568\tvalid_0's multi_logloss: 0.158568\n",
            "[75]\tvalid_0's multi_logloss: 0.158371\tvalid_0's multi_logloss: 0.158371\n",
            "[76]\tvalid_0's multi_logloss: 0.158147\tvalid_0's multi_logloss: 0.158147\n",
            "[77]\tvalid_0's multi_logloss: 0.157962\tvalid_0's multi_logloss: 0.157962\n",
            "[78]\tvalid_0's multi_logloss: 0.157787\tvalid_0's multi_logloss: 0.157787\n",
            "[79]\tvalid_0's multi_logloss: 0.157645\tvalid_0's multi_logloss: 0.157645\n",
            "[80]\tvalid_0's multi_logloss: 0.1575\tvalid_0's multi_logloss: 0.1575\n",
            "[81]\tvalid_0's multi_logloss: 0.157418\tvalid_0's multi_logloss: 0.157418\n",
            "[82]\tvalid_0's multi_logloss: 0.15728\tvalid_0's multi_logloss: 0.15728\n",
            "[83]\tvalid_0's multi_logloss: 0.157152\tvalid_0's multi_logloss: 0.157152\n",
            "[84]\tvalid_0's multi_logloss: 0.157093\tvalid_0's multi_logloss: 0.157093\n",
            "[85]\tvalid_0's multi_logloss: 0.157003\tvalid_0's multi_logloss: 0.157003\n",
            "[86]\tvalid_0's multi_logloss: 0.156914\tvalid_0's multi_logloss: 0.156914\n",
            "[87]\tvalid_0's multi_logloss: 0.156763\tvalid_0's multi_logloss: 0.156763\n",
            "[88]\tvalid_0's multi_logloss: 0.156683\tvalid_0's multi_logloss: 0.156683\n",
            "[89]\tvalid_0's multi_logloss: 0.156584\tvalid_0's multi_logloss: 0.156584\n",
            "[90]\tvalid_0's multi_logloss: 0.156499\tvalid_0's multi_logloss: 0.156499\n",
            "[91]\tvalid_0's multi_logloss: 0.156422\tvalid_0's multi_logloss: 0.156422\n",
            "[92]\tvalid_0's multi_logloss: 0.156327\tvalid_0's multi_logloss: 0.156327\n",
            "[93]\tvalid_0's multi_logloss: 0.156296\tvalid_0's multi_logloss: 0.156296\n",
            "[94]\tvalid_0's multi_logloss: 0.156211\tvalid_0's multi_logloss: 0.156211\n",
            "[95]\tvalid_0's multi_logloss: 0.156175\tvalid_0's multi_logloss: 0.156175\n",
            "[96]\tvalid_0's multi_logloss: 0.156158\tvalid_0's multi_logloss: 0.156158\n",
            "[97]\tvalid_0's multi_logloss: 0.156135\tvalid_0's multi_logloss: 0.156135\n",
            "[98]\tvalid_0's multi_logloss: 0.156124\tvalid_0's multi_logloss: 0.156124\n",
            "[99]\tvalid_0's multi_logloss: 0.15608\tvalid_0's multi_logloss: 0.15608\n",
            "[100]\tvalid_0's multi_logloss: 0.156042\tvalid_0's multi_logloss: 0.156042\n",
            "[101]\tvalid_0's multi_logloss: 0.155968\tvalid_0's multi_logloss: 0.155968\n",
            "[102]\tvalid_0's multi_logloss: 0.155932\tvalid_0's multi_logloss: 0.155932\n",
            "[103]\tvalid_0's multi_logloss: 0.155884\tvalid_0's multi_logloss: 0.155884\n",
            "[104]\tvalid_0's multi_logloss: 0.155813\tvalid_0's multi_logloss: 0.155813\n",
            "[105]\tvalid_0's multi_logloss: 0.155761\tvalid_0's multi_logloss: 0.155761\n",
            "[106]\tvalid_0's multi_logloss: 0.15574\tvalid_0's multi_logloss: 0.15574\n",
            "[107]\tvalid_0's multi_logloss: 0.155757\tvalid_0's multi_logloss: 0.155757\n",
            "[108]\tvalid_0's multi_logloss: 0.155737\tvalid_0's multi_logloss: 0.155737\n",
            "[109]\tvalid_0's multi_logloss: 0.155701\tvalid_0's multi_logloss: 0.155701\n",
            "[110]\tvalid_0's multi_logloss: 0.15569\tvalid_0's multi_logloss: 0.15569\n",
            "[111]\tvalid_0's multi_logloss: 0.155643\tvalid_0's multi_logloss: 0.155643\n",
            "[112]\tvalid_0's multi_logloss: 0.155681\tvalid_0's multi_logloss: 0.155681\n",
            "[113]\tvalid_0's multi_logloss: 0.155704\tvalid_0's multi_logloss: 0.155704\n",
            "[114]\tvalid_0's multi_logloss: 0.155739\tvalid_0's multi_logloss: 0.155739\n",
            "[115]\tvalid_0's multi_logloss: 0.155702\tvalid_0's multi_logloss: 0.155702\n",
            "[116]\tvalid_0's multi_logloss: 0.155745\tvalid_0's multi_logloss: 0.155745\n",
            "[117]\tvalid_0's multi_logloss: 0.155732\tvalid_0's multi_logloss: 0.155732\n",
            "[118]\tvalid_0's multi_logloss: 0.155754\tvalid_0's multi_logloss: 0.155754\n",
            "[119]\tvalid_0's multi_logloss: 0.155753\tvalid_0's multi_logloss: 0.155753\n",
            "[120]\tvalid_0's multi_logloss: 0.155767\tvalid_0's multi_logloss: 0.155767\n",
            "[121]\tvalid_0's multi_logloss: 0.155769\tvalid_0's multi_logloss: 0.155769\n",
            "Early stopping, best iteration is:\n",
            "[111]\tvalid_0's multi_logloss: 0.155643\tvalid_0's multi_logloss: 0.155643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:54:00.428750Z",
          "start_time": "2020-10-05T08:54:00.363125Z"
        },
        "id": "ZUqbSjJvtjrD",
        "outputId": "3bf5cc7c-c18e-463f-c906-03b804433b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(f'{accuracy_score(y, np.argmax(p_val, axis=1)) * 100:.4f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93.4184%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:54:00.469957Z",
          "start_time": "2020-10-05T08:54:00.431515Z"
        },
        "id": "seNf7mE5tjrF",
        "outputId": "7fbcb4b6-fa4d-47d2-fe33-af826346aede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(p_val.shape, p_tst.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(320000, 3) (80000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:54:01.328066Z",
          "start_time": "2020-10-05T08:54:00.472868Z"
        },
        "id": "HHeoTJE7tjrH"
      },
      "source": [
        "np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n",
        "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jTUoT-utjrI"
      },
      "source": [
        "## 피처 중요도 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:54:01.664554Z",
          "start_time": "2020-10-05T08:54:01.331052Z"
        },
        "id": "bpk0BoIytjrJ",
        "outputId": "18e87a0d-32ae-4fb4-b947-8dddbf1ae3f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "imp = pd.DataFrame({'feature': df.columns, 'importance': clf.feature_importances_})\n",
        "imp = imp.sort_values('importance').set_index('feature')\n",
        "imp.plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4d661a0a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc3UP5yPtjrK"
      },
      "source": [
        "## 제출 파일 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:54:01.717722Z",
          "start_time": "2020-10-05T08:54:01.667076Z"
        },
        "id": "0ekA4n-2tjrL",
        "outputId": "95aa3327-cf41-4068-ad4f-97d01b035e21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "sub = pd.read_csv(sample_file, index_col=0)\n",
        "print(sub.shape)\n",
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>320000</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320001</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320002</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320003</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320004</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        class\n",
              "id           \n",
              "320000      0\n",
              "320001      0\n",
              "320002      0\n",
              "320003      0\n",
              "320004      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:54:01.754346Z",
          "start_time": "2020-10-05T08:54:01.720089Z"
        },
        "id": "h29KJuaYtjrO",
        "outputId": "7ee287f5-3896-46eb-ddaf-68b1b17744b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "sub[target_col] = np.argmax(p_tst, axis=1)\n",
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>320000</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320001</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320002</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320003</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320004</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        class\n",
              "id           \n",
              "320000      2\n",
              "320001      0\n",
              "320002      2\n",
              "320003      0\n",
              "320004      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:54:01.788659Z",
          "start_time": "2020-10-05T08:54:01.756610Z"
        },
        "id": "7LcCdan6tjrQ",
        "outputId": "c7642d43-9862-47bf-e85b-a3d4a0e8645f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "sub[target_col].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    40740\n",
              "0    29978\n",
              "1     9282\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-10-05T08:54:01.936033Z",
          "start_time": "2020-10-05T08:54:01.791219Z"
        },
        "id": "7moq2y6htjrR"
      },
      "source": [
        "sub.to_csv(sub_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vogtzaqFtjrT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}