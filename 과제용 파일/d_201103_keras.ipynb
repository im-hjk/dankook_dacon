{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "d_201103_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6Y9QuqWrxIsuMRQBCB3fs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/im-hjk/dankook_dacon/blob/master/d_201103_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOIKg3EKJgnb"
      },
      "source": [
        "#lib import / setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6l38dsYQGY0"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztkKkEMfG41K",
        "outputId": "27f587a4-02c1-4b32-94f5-b2f0d03bd4f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCLLZ74CHM1Z"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "import seaborn as sns\n",
        "\n",
        "import io\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt9q4QIWMozJ"
      },
      "source": [
        "rcParams['figure.figsize'] = (16, 8)\n",
        "plt.style.use('fivethirtyeight')\n",
        "pd.set_option('max_columns', 100)\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KBE3OLeJlqI"
      },
      "source": [
        "#loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_KYMmRJH8pP"
      },
      "source": [
        "main_path = Path('/content/drive/My Drive/Colab Notebooks/dacon_author')\n",
        "feedMe_dir = main_path / 'feed_me' # 기본 feature들 있는 곳\n",
        "medium_dir =  main_path / 'medium' # 중간 결과물 저장하는 곳\n",
        "result_dir =  main_path / 'result' # 최종 결과물 저장하는 곳\n",
        "\n",
        "trn_file = feedMe_dir / 'train.csv'\n",
        "tst_file = feedMe_dir / 'test_x.csv'\n",
        "smp_file = feedMe_dir / 'sample_submission.csv'\n",
        "\n",
        "trn = pd.read_csv( trn_file , encoding = 'utf-8')\n",
        "tst = pd.read_csv( tst_file , encoding = 'utf-8')\n",
        "sub = pd.read_csv( smp_file , encoding = 'utf-8')\n",
        "\n",
        "algo_name = 'keras'\n",
        "feature_name = 'raw'\n",
        "model_name = f'{algo_name}_{feature_name}'\n",
        "sub_file = result_dir / f'{model_name}.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzK7JHWHKOKJ"
      },
      "source": [
        "#preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apvVVLMFJ3pS"
      },
      "source": [
        "#부호 제거\n",
        "def alpha_num(text):\n",
        "    return re.sub(r'[^A-Za-z0-9 ]', '', text)\n",
        "\n",
        "trn['text']=trn['text'].apply(alpha_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fusAb2DvKfqh"
      },
      "source": [
        "#불용어 제거\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stopwords:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "\n",
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \n",
        "             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n",
        "             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n",
        "             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n",
        "             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n",
        "             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n",
        "             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n",
        "             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n",
        "             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n",
        "             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n",
        "             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "             "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S19uQxwPKq2r"
      },
      "source": [
        "#전처리 적용\n",
        "trn['text'] = trn['text'].str.lower()\n",
        "tst['text'] = tst['text'].str.lower()\n",
        "trn['text'] = trn['text'].apply(alpha_num).apply(remove_stopwords)\n",
        "tst['text'] = tst['text'].apply(alpha_num).apply(remove_stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaBfz-BoLzeH"
      },
      "source": [
        "# train test 분리\n",
        "X_train = np.array([x for x in trn['text']])\n",
        "X_test = np.array([x for x in tst['text']])\n",
        "y_train = np.array([x for x in trn['author']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oeVlu63Kz8J"
      },
      "source": [
        "#modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mg9Np-GK5JO"
      },
      "source": [
        "#파라미터 설정\n",
        "vocab_size = 20000\n",
        "embedding_dim = 16\n",
        "max_length = 500\n",
        "padding_type='post'\n",
        "#oov_tok = \"<OOV>\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xDzqu2BK_XW"
      },
      "source": [
        "#tokenizer에 fit\n",
        "tokenizer = Tokenizer(num_words = vocab_size)#, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVqiFucdLAfO"
      },
      "source": [
        "#데이터를 sequence로 변환해주고 padding 해줍니다.\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "train_padded = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "test_padded = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7g7YcbTLCBw"
      },
      "source": [
        "#가벼운 NLP모델 생성\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a1q-z0KLEAc",
        "outputId": "b41e55fc-27d3-4d6b-e4ff-d75014787130",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# compile model\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model summary\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 16)           320000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 24)                408       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 125       \n",
            "=================================================================\n",
            "Total params: 320,533\n",
            "Trainable params: 320,533\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tri1N__LFOC",
        "outputId": "d74c7fbd-00d7-4674-d7c0-4619aee95bba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# fit model\n",
        "num_epochs = 20\n",
        "history = model.fit(train_padded, y_train, \n",
        "                    epochs=num_epochs, verbose=2, \n",
        "                    validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1372/1372 - 8s - loss: 1.5660 - accuracy: 0.2780 - val_loss: 1.5515 - val_accuracy: 0.2812\n",
            "Epoch 2/20\n",
            "1372/1372 - 8s - loss: 1.4248 - accuracy: 0.3999 - val_loss: 1.2760 - val_accuracy: 0.5221\n",
            "Epoch 3/20\n",
            "1372/1372 - 8s - loss: 1.1641 - accuracy: 0.5421 - val_loss: 1.1101 - val_accuracy: 0.5579\n",
            "Epoch 4/20\n",
            "1372/1372 - 12s - loss: 1.0340 - accuracy: 0.5885 - val_loss: 1.0310 - val_accuracy: 0.5925\n",
            "Epoch 5/20\n",
            "1372/1372 - 8s - loss: 0.9492 - accuracy: 0.6218 - val_loss: 0.9778 - val_accuracy: 0.6096\n",
            "Epoch 6/20\n",
            "1372/1372 - 8s - loss: 0.8836 - accuracy: 0.6508 - val_loss: 0.9350 - val_accuracy: 0.6324\n",
            "Epoch 7/20\n",
            "1372/1372 - 8s - loss: 0.8237 - accuracy: 0.6824 - val_loss: 0.9032 - val_accuracy: 0.6471\n",
            "Epoch 8/20\n",
            "1372/1372 - 8s - loss: 0.7701 - accuracy: 0.7067 - val_loss: 0.8893 - val_accuracy: 0.6495\n",
            "Epoch 9/20\n",
            "1372/1372 - 8s - loss: 0.7267 - accuracy: 0.7274 - val_loss: 0.8568 - val_accuracy: 0.6673\n",
            "Epoch 10/20\n",
            "1372/1372 - 8s - loss: 0.6848 - accuracy: 0.7446 - val_loss: 0.8508 - val_accuracy: 0.6707\n",
            "Epoch 11/20\n",
            "1372/1372 - 8s - loss: 0.6505 - accuracy: 0.7582 - val_loss: 0.8169 - val_accuracy: 0.6927\n",
            "Epoch 12/20\n",
            "1372/1372 - 8s - loss: 0.6181 - accuracy: 0.7734 - val_loss: 0.8457 - val_accuracy: 0.6795\n",
            "Epoch 13/20\n",
            "1372/1372 - 8s - loss: 0.5919 - accuracy: 0.7842 - val_loss: 0.8179 - val_accuracy: 0.6951\n",
            "Epoch 14/20\n",
            "1372/1372 - 8s - loss: 0.5639 - accuracy: 0.7957 - val_loss: 0.7997 - val_accuracy: 0.7085\n",
            "Epoch 15/20\n",
            "1372/1372 - 8s - loss: 0.5438 - accuracy: 0.8032 - val_loss: 0.7971 - val_accuracy: 0.7139\n",
            "Epoch 16/20\n",
            "1372/1372 - 8s - loss: 0.5234 - accuracy: 0.8121 - val_loss: 0.8237 - val_accuracy: 0.6998\n",
            "Epoch 17/20\n",
            "1372/1372 - 8s - loss: 0.5071 - accuracy: 0.8170 - val_loss: 0.8130 - val_accuracy: 0.7104\n",
            "Epoch 18/20\n",
            "1372/1372 - 8s - loss: 0.4880 - accuracy: 0.8243 - val_loss: 0.8217 - val_accuracy: 0.7127\n",
            "Epoch 19/20\n",
            "1372/1372 - 8s - loss: 0.4711 - accuracy: 0.8317 - val_loss: 0.8108 - val_accuracy: 0.7179\n",
            "Epoch 20/20\n",
            "1372/1372 - 8s - loss: 0.4594 - accuracy: 0.8362 - val_loss: 0.8352 - val_accuracy: 0.7163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWo30Cl_LGXE",
        "outputId": "1ed9c94c-a395-4514-e83b-7330fb42a408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# predict values\n",
        "pred = model.predict_proba(test_padded)\n",
        "# WARNING:tensorflow:From <ipython-input-18-9e01c6cf1b05>:2: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
        "# Instructions for updating:\n",
        "# Please use `model.predict()` instead."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-9e01c6cf1b05>:2: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use `model.predict()` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm7m_p9IMDmh"
      },
      "source": [
        "#sub f"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGt68le_MFbU"
      },
      "source": [
        "# submission\n",
        "sub[['0','1','2','3','4']] = pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W1UQ6duMH5j"
      },
      "source": [
        "sub.to_csv(sub_file, index = False, encoding = 'utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}